{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT - Out of the Box\n",
    "\n",
    "In this notebook, we will test the performance of an out-of-the-box BERT model on CommonsenseQA. I follow the tutorial here: https://github.com/jalammar/jalammar.github.io/blob/master/notebooks/bert/A_Visual_Notebook_to_Using_BERT_for_the_First_Time.ipynb\n",
    "\n",
    "I've implemented the Hugginface transformers library. \n",
    "\n",
    "I referred to the Commonsense QA repo and code to understand how the authors of this work establiahsed their baseline using BERT. This is the link to their code: https://github.com/jonathanherzig/commonsenseqa/blob/master/bert/run_commonsense_qa.py\n",
    "\n",
    "From this repo (README): https://github.com/jonathanherzig/commonsenseqa\n",
    "\n",
    "Their work is far more advanced and complicated than maybe what I want to do at this time. But I refer to their work to understand the set up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import warnings\n",
    "\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from transformers import BertTokenizer, TFBertModel, BertConfig\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import time \n",
    "configuration = BertConfig() \n",
    "from IPython.display import Image \n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import pickle\n",
    "\n",
    "runtype=\"cpu\"\n",
    "\n",
    "print(\"Run type:\", runtype)\n",
    "print(tf.__version__) \n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(\"Num CPUs Available: \",\n",
    "      len(tf.config.experimental.list_physical_devices('CPU')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dataset\n",
    "\n",
    "It's in the dataset folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answerKey</th>\n",
       "      <th>id</th>\n",
       "      <th>question_concept</th>\n",
       "      <th>choices</th>\n",
       "      <th>stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>075e483d21c29a511267ef62bedc0461</td>\n",
       "      <td>punishing</td>\n",
       "      <td>[{'label': 'A', 'text': 'ignore'}, {'label': '...</td>\n",
       "      <td>The sanctions against the school were a punish...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>61fe6e879ff18686d7552425a36344c8</td>\n",
       "      <td>people</td>\n",
       "      <td>[{'label': 'A', 'text': 'race track'}, {'label...</td>\n",
       "      <td>Sammy wanted to go to where the people were.  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>4c1cb0e95b99f72d55c068ba0255c54d</td>\n",
       "      <td>choker</td>\n",
       "      <td>[{'label': 'A', 'text': 'jewelry store'}, {'la...</td>\n",
       "      <td>To locate a choker not located in a jewelry bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D</td>\n",
       "      <td>02e821a3e53cb320790950aab4489e85</td>\n",
       "      <td>highway</td>\n",
       "      <td>[{'label': 'A', 'text': 'united states'}, {'la...</td>\n",
       "      <td>Google Maps and other highway and street GPS s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C</td>\n",
       "      <td>23505889b94e880c3e89cff4ba119860</td>\n",
       "      <td>fox</td>\n",
       "      <td>[{'label': 'A', 'text': 'pretty flowers.'}, {'...</td>\n",
       "      <td>The fox walked from the city into the forest, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  answerKey                                id question_concept  \\\n",
       "0         A  075e483d21c29a511267ef62bedc0461        punishing   \n",
       "1         B  61fe6e879ff18686d7552425a36344c8           people   \n",
       "2         A  4c1cb0e95b99f72d55c068ba0255c54d           choker   \n",
       "3         D  02e821a3e53cb320790950aab4489e85          highway   \n",
       "4         C  23505889b94e880c3e89cff4ba119860              fox   \n",
       "\n",
       "                                             choices  \\\n",
       "0  [{'label': 'A', 'text': 'ignore'}, {'label': '...   \n",
       "1  [{'label': 'A', 'text': 'race track'}, {'label...   \n",
       "2  [{'label': 'A', 'text': 'jewelry store'}, {'la...   \n",
       "3  [{'label': 'A', 'text': 'united states'}, {'la...   \n",
       "4  [{'label': 'A', 'text': 'pretty flowers.'}, {'...   \n",
       "\n",
       "                                                stem  \n",
       "0  The sanctions against the school were a punish...  \n",
       "1  Sammy wanted to go to where the people were.  ...  \n",
       "2  To locate a choker not located in a jewelry bo...  \n",
       "3  Google Maps and other highway and street GPS s...  \n",
       "4  The fox walked from the city into the forest, ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data(file):\n",
    "    lines = []\n",
    "    with open(file, 'rb') as json_file:\n",
    "        for json_line in json_file:\n",
    "            lines.append(json.loads(json_line))\n",
    "        data = json_normalize(lines)\n",
    "        data.columns = data.columns.map(lambda x: x.split(\".\")[-1])\n",
    "    return data\n",
    "# os.chdir('w266-commonsenseqa/BERT_oob)\n",
    "train = load_data('../dataset/train_rand_split.jsonl')\n",
    "dev = load_data('../dataset/dev_rand_split.jsonl')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps\n",
    "\n",
    "1. Import training examples\n",
    "2. Process it\n",
    "    - Format input into something BERT can work with, including `[CLS]` and `[SEP]`\n",
    "    - We were thinking which label is correct: \n",
    "    - Tokenize \n",
    "    - Create an output layer using softmax. \n",
    "3. Train it\n",
    "    - Specify how many layers of BERT to fine tune\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT base model (uncased)\n",
    "\n",
    "From: https://huggingface.co/bert-base-uncased\n",
    "\n",
    "> Pretrained model on English language using a masked language modeling (MLM) objective. It was introduced in this paper and first released in this repository. This model is uncased: it does not make a difference between english and English.\n",
    "> \n",
    "> Disclaimer: The team releasing BERT did not write a model card for this model so this model card has been written by the Hugging Face team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each question, there are five answer choices. Only one of them is correct.\n",
    "\n",
    "For BERT, the first thought was to have all five answers attached to each question, and the model would choose one of the five responses. This is how it's originally done in the CommonsenseQA paper.\n",
    "\n",
    "```\n",
    "[CLS] Question text here [SEP] Ans choice A [SEP] Ans choice B [SEP] Ans choice C [SEP] Ans choice D [SEP] Ans choice E [SEP]\n",
    "```\n",
    "\n",
    "It seems complicated, however, and requires a significant lift. So for now, let me try creating five question-answer pairs for each question. Like this:\n",
    "\n",
    "```\n",
    "[CLS] Question text here [SEP] Ans choice A [SEP]\n",
    "[CLS] Question text here [SEP] Ans choice B [SEP]\n",
    "[CLS] Question text here [SEP] Ans choice C [SEP]\n",
    "[CLS] Question text here [SEP] Ans choice D [SEP]\n",
    "[CLS] Question text here [SEP] Ans choice E [SEP]\n",
    "```\n",
    "\n",
    "Only one of the above 5 inputs will have a positive label for being the correct answer. The rest will have 0. The problem with this model is that we're evaluating each choice separately to see if it looks like a right answer at all. But I think it's important for the model to know how the answer choices compare to each other as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "lab_order = {\"A\": 0, \"B\":1, \"C\":2, \"D\":3, \"E\":4}\n",
    "\n",
    "class InputExample(object):\n",
    "    \"\"\"A single multiple choice question.\"\"\"\n",
    "    # This class is adapted from https://github.com/jonathanherzig/commonsenseqa/blob/master/bert/run_commonsense_qa.py\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            qid,\n",
    "            question,\n",
    "            answer,\n",
    "            label):\n",
    "        \"\"\"Construct an instance.\"\"\"\n",
    "        self.qid = qid\n",
    "        self.question = question  # e.g., 'The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change?'\n",
    "        self.answer = answer      # e.g., \"ignore\" if choice label is A \n",
    "        self.label = label        # e.g., If correct answer, 1. Otherwise 0. \n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"QUESTION: {}\\nANSWER  : {}\\nLABEL   : {}\".format(self.question, self.answer, self.label)\n",
    "    \n",
    "    \n",
    "def create_example(row, choice_num):\n",
    "    qid = row.id\n",
    "    \n",
    "    # Question: Just take it from stem \n",
    "    question = row.stem\n",
    "    \n",
    "    # Answer choice \n",
    "    label = int(row[\"answerKey\"] == choice_num)  # If the answer key is equal to the answer choice number, mark 1 \n",
    "    answer = row[\"choices\"][lab_order[choice_num]][\"text\"]         # actual ans text \n",
    "    \n",
    "    return InputExample(qid, question, answer, label) \n",
    "    \n",
    "    \n",
    "def process_examples(data):\n",
    "    examples = []\n",
    "    labels = []\n",
    "    questions = []\n",
    "    anscands = []\n",
    "    \n",
    "    \n",
    "    for index, row in data.iterrows(): \n",
    "        for letter in lab_order.keys():\n",
    "            example = create_example(row, letter)\n",
    "            examples.append(example)\n",
    "            \n",
    "            questions.append(example.question)\n",
    "            anscands.append(example.answer)\n",
    "            labels.append(example.label)\n",
    "    labels = np.array(labels)\n",
    "        \n",
    "    encoded_example = tokenizer(questions, anscands, padding=True, truncation=True, return_tensors='tf')\n",
    "    \n",
    "    # Make the encoded example a dictionary of np arrays\n",
    "    for key in encoded_example:\n",
    "        encoded_example[key] = np.array(encoded_example[key])\n",
    "        \n",
    "    clean_encoded_example = [\n",
    "        encoded_example[\"input_ids\"],\n",
    "        encoded_example[\"attention_mask\"],\n",
    "        encoded_example[\"token_type_ids\"]\n",
    "    ]\n",
    "            \n",
    "    return examples, clean_encoded_example, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_train_eg, bert_inputs_train_tiny, bert_labs_train_tiny = \\\n",
    "process_examples(train.iloc[0:2])\n",
    "\n",
    "dev_eg, dev_encoded_eg, dev_labs = process_examples(dev)\n",
    "train_eg, train_encoded_eg, train_labs = process_examples(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process dev and training data\n",
    "\n",
    "`print(dev_eg[0])`\n",
    "\n",
    "```QUESTION: A revolving door is convenient for two direction travel, but it also serves as a security measure at a what?\n",
    "ANSWER  : bank\n",
    "LABEL   : 1```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My encoded examples are all saved in `dev_encoded_eg`. Inside it I an see `input_ids`, `token_type_ids` and `attention_mask`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was a little concerned that I got a warning about no max length. But it seems like every single input has a max length with enough padding.\n",
    "\n",
    "`print(tiny_train_eg[0])\n",
    "print(tiny_train_eg[1])\n",
    "print(tiny_train_eg[2])`\n",
    "\n",
    "    QUESTION: The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change?\n",
    "    ANSWER  : ignore\n",
    "    LABEL   : 1\n",
    "    QUESTION: The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change?\n",
    "    ANSWER  : enforce\n",
    "    LABEL   : 0\n",
    "    QUESTION: The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change?\n",
    "    ANSWER  : authoritarian\n",
    "    LABEL   : 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION: The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change?\n",
      "ANSWER  : ignore\n",
      "LABEL   : 1\n",
      "QUESTION: The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change?\n",
      "ANSWER  : enforce\n",
      "LABEL   : 0\n",
      "QUESTION: The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change?\n",
      "ANSWER  : authoritarian\n",
      "LABEL   : 0\n"
     ]
    }
   ],
   "source": [
    "print(tiny_train_eg[0])\n",
    "print(tiny_train_eg[1])\n",
    "print(tiny_train_eg[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some more notes**\n",
    "\n",
    "* The `[CLS]` token is important. It stands for classification and it is there to represent sentence-level classification. It's added in the beginning of each sentence because the training task is sentence classification (e.g., *correct answer or incorrect answer?*)\n",
    "* BERT will output a vector for each input token. Each vector is the size of *hidden_size*, which s 768 for BERT Base that we're using. For a classification task like we have at hand, we will focus on the output of just the `[CLS]` token. \n",
    "\n",
    "* The BERT output vector for `[CLS]` token can now be used as an input for a classifier task. We can do a simple feed-forward neural network plus softmax to see if it returns 1 or 0, or whether the answer is correct or incorrect for the question. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image(\"img/bert-tasks.png\") # source: http://jalammar.github.io/illustrated-bert/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the classification, maybe what we could do is, for each question, go through the five relevant examples. Then pick the one with the highest predicted output score. Like in the \"multiple choice\" diagram at the bottom of this image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image(\"img/openai-input transformations.png\")  # source: http://jalammar.github.io/illustrated-bert/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Game plan\n",
    "\n",
    "I'll be following the tutorial on: http://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/, but for specifically commonsenseQA. Here are the steps from the tutorial.\n",
    "\n",
    "1. Embed all sentences. Let's look at the output from the BERT model for our inputs. \n",
    "2. The tutorial says do a train/test split. We don't need this 'cause our data came separate.\n",
    "3. Train the logistic regressio model using the training set. This is training on the output of BERT. I will need to create a FFNN to attach at the end of BERT. See what it comes back with. \n",
    "4. (Optional for now) For each question, pick the answer with the highest score. \n",
    "5. Then, evaluate against true answers. The evaluation metric will be % of questions with the correct answers out of all questions. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Embed all sentences. \n",
    "\n",
    "I've already formatted the CommonsenseQA inpts to be fed into the BERT model. Let's look at the output from the BERT model for our inputs. It should have a 768-long vector for each input token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# bert_model = TFBertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bert (TFBertMainLayer)       multiple                  109482240 \n",
      "=================================================================\n",
      "Total params: 109,482,240\n",
      "Trainable params: 109,482,240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# bert_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(bert_inputs_train_tiny[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Each example has the max num of tokens tokens. \n",
    "# # Each token yields a vector of 768 numbers after coming out of the bert model!\n",
    "\n",
    "# bert_sequence = bert_model(bert_inputs_train_tiny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([200, 36, 768])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # This task is token level masking and prediction\n",
    "# bert_sequence[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    TensorShape([200, 36, 768])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CLS token I want is here: (for example number 123)\n",
    "# bert_sequence[0][123, 0, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([200, 768])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # This task is, does this sentence follow the previous? Yes/no\n",
    "# bert_sequence[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    TensorShape([200, 768])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sunday morning retry "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = 'oob_bert_classify_{runtype}_{ts}'.format(runtype=runtype, ts=int(time.time()))\n",
    "tensorboard = TensorBoard(log_dir='models/logs/{}'.format(NAME))\n",
    "\n",
    "def classification_model(max_len):\n",
    "    \"\"\"Implementation of classification model.\n",
    "    Returns: model\"\"\"\n",
    "    ## BERT encoder\n",
    "    encoder = TFBertModel.from_pretrained(\"bert-base-uncased\")\n",
    "    ## QA Model\n",
    "    input_ids = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name=\"InputID\")\n",
    "    attention_mask = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name=\"AttentionMask\")\n",
    "    token_type_ids = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name=\"TokenTypeID\")\n",
    "    embedding = encoder(\n",
    "        [input_ids, attention_mask, token_type_ids]\n",
    "    )[0]\n",
    "    # Feed inputs through the bert model, \n",
    "    # then take just the vector associated with first token [CLS]\n",
    "    bert_cls_output = embedding[:,0]\n",
    "    # These are the layers that come after Bert.\n",
    "    dense = tf.keras.layers.Dense(256, activation='relu', name='dense')(bert_cls_output)\n",
    "    # Output layer to predict correct answer. \n",
    "    # For the future, we may modify it to choose the max candidate answer of each question\n",
    "    # for now, just predict from 0 to 1 whether this looks like a correct answer. \n",
    "    pred = tf.keras.layers.Dense(1, activation='sigmoid', name='correct')(dense)\n",
    "    model = tf.keras.models.Model(inputs=[input_ids, token_type_ids, attention_mask],\n",
    "                                  outputs=pred)\n",
    "    model.compile(loss=\"binary_crossentropy\", \n",
    "                  optimizer=\"adam\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 200)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 200)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 200)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model_1 (TFBertModel)   ((None, 200, 768), ( 109482240   input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(None, 768)]        0           tf_bert_model_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          196864      tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "correct (Dense)                 (None, 1)            257         dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 109,679,361\n",
      "Trainable params: 109,679,361\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "max_length= len(bert_inputs_train_tiny[0])   # num max token \n",
    "BertClassifierModel = classification_model(max_len=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 200) for input Tensor(\"input_1:0\", shape=(None, 200), dtype=int32), but it was called on an input with incompatible shape (None, 36).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 200) for input Tensor(\"input_3:0\", shape=(None, 200), dtype=int32), but it was called on an input with incompatible shape (None, 36).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 200) for input Tensor(\"input_2:0\", shape=(None, 200), dtype=int32), but it was called on an input with incompatible shape (None, 36).\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 200) for input Tensor(\"input_1:0\", shape=(None, 200), dtype=int32), but it was called on an input with incompatible shape (None, 36).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 200) for input Tensor(\"input_3:0\", shape=(None, 200), dtype=int32), but it was called on an input with incompatible shape (None, 36).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 200) for input Tensor(\"input_2:0\", shape=(None, 200), dtype=int32), but it was called on an input with incompatible shape (None, 36).\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "7/7 [==============================] - 3s 375ms/step - loss: 1.0844 - accuracy: 0.6000\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'end' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-8b9b06619c56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Execution duration:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'end' is not defined"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "BertClassifierModel.fit(\n",
    "    [bert_inputs_train_tiny[0],\n",
    "    bert_inputs_train_tiny[1],\n",
    "    bert_inputs_train_tiny[2]],\n",
    "    bert_labs_train_tiny, \n",
    "    epochs=1)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Execution duration:\", end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train\n",
    "\n",
    "On training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 48705)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 48705)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, 48705)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model_2 (TFBertModel)   ((None, 48705, 768), 109482240   input_4[0][0]                    \n",
      "                                                                 input_5[0][0]                    \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_1 (Te [(None, 768)]        0           tf_bert_model_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          196864      tf_op_layer_strided_slice_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "correct (Dense)                 (None, 1)            257         dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 109,679,361\n",
      "Trainable params: 109,679,361\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# train_eg, train_encoded_eg, train_labs \n",
    "\n",
    "max_length= len(train_encoded_eg[0])   # num max token \n",
    "BertClassifierModel = classification_model(max_len=max_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 48705) for input Tensor(\"input_4:0\", shape=(None, 48705), dtype=int32), but it was called on an input with incompatible shape (None, 75).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 48705) for input Tensor(\"input_6:0\", shape=(None, 48705), dtype=int32), but it was called on an input with incompatible shape (None, 75).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 48705) for input Tensor(\"input_5:0\", shape=(None, 48705), dtype=int32), but it was called on an input with incompatible shape (None, 75).\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 48705) for input Tensor(\"input_4:0\", shape=(None, 48705), dtype=int32), but it was called on an input with incompatible shape (None, 75).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 48705) for input Tensor(\"input_6:0\", shape=(None, 48705), dtype=int32), but it was called on an input with incompatible shape (None, 75).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 48705) for input Tensor(\"input_5:0\", shape=(None, 48705), dtype=int32), but it was called on an input with incompatible shape (None, 75).\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "1523/1523 [==============================] - 1409s 925ms/step - loss: 0.5082 - accuracy: 0.7991\n",
      "Execution duration: 1426.2172222137451\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "BertClassifierModel.fit(\n",
    "    [   train_encoded_eg[0],\n",
    "        train_encoded_eg[1],\n",
    "        train_encoded_eg[2]],\n",
    "    train_labs, \n",
    "    epochs=3,\n",
    "    # Insert validation data\n",
    "    validation_data=(\n",
    "        [dev_encoded_eg[0],\n",
    "         dev_encoded_eg[1],\n",
    "         dev_encoded_eg[2]\n",
    "        ], dev_labs\n",
    "    ),\n",
    "    # Log the training info on tensorboard\n",
    "    callbacks=[tensorboard])\n",
    "\n",
    "end = time.time()\n",
    "print(\"Execution duration in minutes:\", (end - start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = BertClassifierModel.predict(\n",
    "    [dev_encoded_eg[0],\n",
    "         dev_encoded_eg[1],\n",
    "         dev_encoded_eg[2]\n",
    "        ])\n",
    "\n",
    "location=\"models/predictions/BertClassifierModel_{}_dev_predictions\".format(runtype)\n",
    "pickle_out = open(location, \"wb\")\n",
    "pickle.dump(predictions, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/haeranglee_berkeley_edu/anaconda3/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /home/haeranglee_berkeley_edu/anaconda3/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: models/bert_classification_1018/assets\n"
     ]
    }
   ],
   "source": [
    "location='models/{NAME}.h5'.format(NAME=NAME)\n",
    "\n",
    "BertClassifierModel.save(location, save_format='tf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 48705) for input Tensor(\"input_4:0\", shape=(None, 48705), dtype=int32), but it was called on an input with incompatible shape (None, 68).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 48705) for input Tensor(\"input_6:0\", shape=(None, 48705), dtype=int32), but it was called on an input with incompatible shape (None, 68).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 48705) for input Tensor(\"input_5:0\", shape=(None, 48705), dtype=int32), but it was called on an input with incompatible shape (None, 68).\n",
      "191/191 [==============================] - 57s 299ms/step - loss: 0.5026 - accuracy: 0.8000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5025756359100342, 0.800000011920929]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BertClassifierModel.evaluate(dev_encoded_eg, dev_labs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1523/1523 [==============================] - 1414s 929ms/step - loss: 0.5026 - accuracy: 0.8000\n",
      "Epoch 2/2\n",
      "1523/1523 [==============================] - 1412s 927ms/step - loss: 0.5023 - accuracy: 0.8000\n",
      "Execution duration in minutes: 47.13618437846502\n",
      "INFO:tensorflow:Assets written to: models/bert_classification_1018_3epochs/assets\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "BertClassifierModel.fit(\n",
    "    [train_encoded_eg[0],\n",
    "    train_encoded_eg[1],\n",
    "    train_encoded_eg[2]],\n",
    "    train_labs, \n",
    "    epochs=2)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Execution duration in minutes:\", (end - start)/60)\n",
    "BertClassifierModel.save('models/bert_classification_1018_3epochs', save_format='tf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191/191 [==============================] - 57s 300ms/step - loss: 0.5013 - accuracy: 0.8000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5012827515602112, 0.800000011920929]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BertClassifierModel.evaluate(dev_encoded_eg, dev_labs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
