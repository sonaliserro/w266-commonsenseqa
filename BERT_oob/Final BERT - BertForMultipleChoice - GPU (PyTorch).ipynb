{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"colab":{"name":"Final BERT - BertForMultipleChoice - GPU (PyTorch).ipynb","provenance":[{"file_id":"16jimPKHW2EGAJXrvdzC21PMJXcu_fSWT","timestamp":1603701182354},{"file_id":"1IoA97lm1Qo7QHO3DOkIh6Rt3TL0rMeQl","timestamp":1603690281133},{"file_id":"197hWAcNFBiocXPlpzNhfV4TMesSzX3iz","timestamp":1603660383162}],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"ZoKkVIxPld2L"},"source":["# BERT - Out of the Box\n","\n","In this notebook, we will test the performance of an out-of-the-box BERT model on CommonsenseQA. I follow the tutorial here: https://github.com/jalammar/jalammar.github.io/blob/master/notebooks/bert/A_Visual_Notebook_to_Using_BERT_for_the_First_Time.ipynb\n","\n","I've implemented the Hugginface transformers library. \n","\n","I referred to the Commonsense QA repo and code to understand how the authors of this work establiahsed their baseline using BERT. This is the link to their code: https://github.com/jonathanherzig/commonsenseqa/blob/master/bert/run_commonsense_qa.py\n","\n","From this repo (README): https://github.com/jonathanherzig/commonsenseqa\n","\n","Their work is far more advanced and complicated than maybe what I want to do at this time. But I refer to their work to understand the set up."]},{"cell_type":"code","metadata":{"id":"n6w5XpvLbqgi","executionInfo":{"status":"ok","timestamp":1603701856981,"user_tz":420,"elapsed":4038,"user":{"displayName":"Haerang Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0EKtbt3OiquluDVkbIbNSiQmtCnognF7CujF_=s64","userId":"05995372446527155749"}},"outputId":"eef6efc2-a631-4e9d-e1db-6c2371db91e3","colab":{"base_uri":"https://localhost:8080/","height":332}},"source":["!pip install pytorch_pretrained_bert"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pytorch_pretrained_bert in /usr/local/lib/python3.6/dist-packages (0.6.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n","Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.6.0+cu101)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.41.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.18.5)\n","Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.16.4)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2020.6.20)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.25.10)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (0.16.0)\n","Requirement already satisfied: botocore<1.20.0,>=1.19.4 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (1.19.4)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.10.0)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.3.3)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.20.0,>=1.19.4->boto3->pytorch_pretrained_bert) (2.8.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.20.0,>=1.19.4->boto3->pytorch_pretrained_bert) (1.15.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AvsHc_ZjcFwH","executionInfo":{"status":"ok","timestamp":1603701859028,"user_tz":420,"elapsed":6072,"user":{"displayName":"Haerang Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0EKtbt3OiquluDVkbIbNSiQmtCnognF7CujF_=s64","userId":"05995372446527155749"}},"outputId":"f96dfd14-57e3-4d97-92f7-f625ba02bb5b","colab":{"base_uri":"https://localhost:8080/","height":55}},"source":["!pip install urllib3==1.25.10"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: urllib3==1.25.10 in /usr/local/lib/python3.6/dist-packages (1.25.10)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bK3n6NlJZGwy","executionInfo":{"status":"ok","timestamp":1603701861165,"user_tz":420,"elapsed":8197,"user":{"displayName":"Haerang Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0EKtbt3OiquluDVkbIbNSiQmtCnognF7CujF_=s64","userId":"05995372446527155749"}},"outputId":"73a3ecf5-8ee0-47a9-894b-b64108b731d8","colab":{"base_uri":"https://localhost:8080/","height":401}},"source":["!pip install transformers"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.4.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: tokenizers==0.9.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.2)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.94)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.25.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BPGE-JhkZLeg","executionInfo":{"status":"ok","timestamp":1603701861166,"user_tz":420,"elapsed":8188,"user":{"displayName":"Haerang Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0EKtbt3OiquluDVkbIbNSiQmtCnognF7CujF_=s64","userId":"05995372446527155749"}},"outputId":"bbad827e-b06f-4e22-ef32-d588fcbaf777","colab":{"base_uri":"https://localhost:8080/","height":72}},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/My\\ Drive/NLP/w266-commonsenseqa/BERT_oob"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/My Drive/MIDS/NLP/w266-commonsenseqa/BERT_oob\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uyGfEdGFld2M","executionInfo":{"status":"ok","timestamp":1603701861167,"user_tz":420,"elapsed":8178,"user":{"displayName":"Haerang Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0EKtbt3OiquluDVkbIbNSiQmtCnognF7CujF_=s64","userId":"05995372446527155749"}}},"source":["import logging\n","import numpy as np\n","import pandas as pd\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","import json\n","from pandas.io.json import json_normalize\n","\n","from transformers import BertTokenizer, BertModel, BertConfig\n","import torch\n","from torch.utils.tensorboard import SummaryWriter\n","from sklearn import metrics\n","\n","from datetime import datetime\n","import pytz\n","# configuration = BertConfig() \n","from collections import defaultdict \n","import pickle "],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"fSPD-txe6FYb","executionInfo":{"status":"ok","timestamp":1603701861167,"user_tz":420,"elapsed":8170,"user":{"displayName":"Haerang Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0EKtbt3OiquluDVkbIbNSiQmtCnognF7CujF_=s64","userId":"05995372446527155749"}}},"source":["ts = datetime.now(pytz.timezone('US/Pacific')).strftime(\"%Y%m%d_%H%M%S\")\n"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"oxMS4iqX6Ds6","executionInfo":{"status":"ok","timestamp":1603701861168,"user_tz":420,"elapsed":8162,"user":{"displayName":"Haerang Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0EKtbt3OiquluDVkbIbNSiQmtCnognF7CujF_=s64","userId":"05995372446527155749"}},"outputId":"ec317500-7504-405a-e1ca-e9b34e7b5776","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["runtype=\"full\" # versus tiny\n","NAME = 'BertForMultipleChoice__{runtype}_{ts}'.format(runtype=runtype, ts=ts)\n","# Logs for tensorboard will be saved in the following directory \n","writer = SummaryWriter(\"runs/\"+ NAME)\n","\n","print(\"Model NAME:\", NAME)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Model NAME: BertForMultipleChoice__full_20201026_014420\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FaFgHDcc6GI1","executionInfo":{"status":"ok","timestamp":1603701861168,"user_tz":420,"elapsed":8152,"user":{"displayName":"Haerang Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0EKtbt3OiquluDVkbIbNSiQmtCnognF7CujF_=s64","userId":"05995372446527155749"}},"outputId":"c4e2f447-fb5b-4fbb-c1b6-82975f995fbd","colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["# To use tensorboard in Google Colab, run this:\n","%load_ext tensorboard\n","\n","# Tensorboard can be viewed with the following command\n","# %tensorboard --logdir logs"],"execution_count":19,"outputs":[{"output_type":"stream","text":["The tensorboard extension is already loaded. To reload it, use:\n","  %reload_ext tensorboard\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zPEAD2OAzdvH","executionInfo":{"status":"ok","timestamp":1603701861169,"user_tz":420,"elapsed":8144,"user":{"displayName":"Haerang Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0EKtbt3OiquluDVkbIbNSiQmtCnognF7CujF_=s64","userId":"05995372446527155749"}}},"source":["# These were supposed to be fed in as .py arguments\n","# I copied them over from the BertForMultipleChoice example doc.\n","# Since I'm running on Jupyter notebook rather than a .py script, \n","# I and created a class to hold all the args \n","# Adapted from https://github.com/rodgzilla/pytorch-pretrained-BERT/blob/dcb50eaa4b80d3ab75d373c36780c80fb47cfd97/examples/run_swag.py\n","\n","logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n","                    datefmt = '%m/%d/%Y %H:%M:%S',\n","                    level = logging.INFO)\n","logger = logging.getLogger(__name__)\n","\n","# These were supposed to be fed in as .py arguments\n","# but for jupyter notebook, I cheated and created a class to hold all the args \n","\n","class arg_holder():\n","    def __init__(self):\n","        self.data_dir = '../dataset/'\n","        self.output_dir = 'bfmc/'\n","        self.bert_model = 'bert-base-uncased'\n","        \n","        self.max_seq_length = 128\n","        self.do_train = True\n","        self.do_eval = False\n","        self.do_lower_case = True\n","        self.train_batch_size = 32\n","        self.eval_batch_size = 8\n","        self.learning_rate = 5e-5\n","        self.num_train_epochs = 3\n","        self.warmup_proportion = 0\n","        self.no_cuda = False\n","        self.local_rank = -1\n","        self.seed = 42\n","        self.gradient_accumulation_steps = 1\n","        self.optimize_on_cpu=False\n","        self.fp16 = False\n","        self.loss_scale = 128\n","args = arg_holder()"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"5Xt_Trih1o0-","executionInfo":{"status":"ok","timestamp":1603701861169,"user_tz":420,"elapsed":8137,"user":{"displayName":"Haerang Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0EKtbt3OiquluDVkbIbNSiQmtCnognF7CujF_=s64","userId":"05995372446527155749"}}},"source":[""],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"4eFkv7pild2x","executionInfo":{"status":"ok","timestamp":1603701861170,"user_tz":420,"elapsed":8131,"user":{"displayName":"Haerang Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0EKtbt3OiquluDVkbIbNSiQmtCnognF7CujF_=s64","userId":"05995372446527155749"}}},"source":["from tqdm import tqdm, trange\n","\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from torch.utils.data.distributed import DistributedSampler\n","\n","# from pytorch_pretrained_bert.tokenization import BertTokenizer\n","# from pytorch_pretrained_bert.modeling import BertForMultipleChoice\n","# from pytorch_pretrained_bert.optimization import BertAdam\n","# from pytorch_pretrained_bert.file_utils import PYTORCH_PRETRAINED_BERT_CACHE\n"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"LE1aTzFFld2z","executionInfo":{"status":"ok","timestamp":1603701861170,"user_tz":420,"elapsed":8123,"user":{"displayName":"Haerang Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0EKtbt3OiquluDVkbIbNSiQmtCnognF7CujF_=s64","userId":"05995372446527155749"}},"outputId":"8369bcca-5326-48c0-bc03-4d2aa9eacb83","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["if args.local_rank == -1 or args.no_cuda:\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\")\n","    n_gpu = torch.cuda.device_count()\n","else:\n","    device = torch.device(\"cuda\", args.local_rank)\n","    n_gpu = 1\n","    # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n","    torch.distributed.init_process_group(backend='nccl')\n","    if args.fp16:\n","        logger.info(\"16-bits training currently not supported in distributed training\")\n","        args.fp16 = False # (see https://github.com/pytorch/pytorch/pull/13496)\n","logger.info(\"device %s n_gpu %d distributed training %r\", device, n_gpu, bool(args.local_rank != -1))\n"],"execution_count":22,"outputs":[{"output_type":"stream","text":["10/26/2020 08:44:20 - INFO - __main__ -   device cuda n_gpu 1 distributed training False\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"Eughqxcdld2Q"},"source":["## Import dataset\n","\n","It's in the dataset folder."]},{"cell_type":"code","metadata":{"id":"yrq39HMHld2R","executionInfo":{"status":"ok","timestamp":1603701861872,"user_tz":420,"elapsed":8807,"user":{"displayName":"Haerang Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0EKtbt3OiquluDVkbIbNSiQmtCnognF7CujF_=s64","userId":"05995372446527155749"}},"outputId":"0f92391d-07d8-4237-8bc2-1d9f14f5936f","colab":{"base_uri":"https://localhost:8080/","height":375}},"source":["def load_data(file):\n","    lines = []\n","    with open(file, 'rb') as json_file:\n","        for json_line in json_file:\n","            lines.append(json.loads(json_line))\n","        data = json_normalize(lines)\n","        data.columns = data.columns.map(lambda x: x.split(\".\")[-1])\n","    return data\n","# os.chdir('w266-commonsenseqa/BERT_oob)\n","train = load_data('../dataset/train_rand_split.jsonl')\n","dev = load_data('../dataset/dev_rand_split.jsonl')\n","train.head()"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>answerKey</th>\n","      <th>id</th>\n","      <th>question_concept</th>\n","      <th>choices</th>\n","      <th>stem</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>A</td>\n","      <td>075e483d21c29a511267ef62bedc0461</td>\n","      <td>punishing</td>\n","      <td>[{'label': 'A', 'text': 'ignore'}, {'label': '...</td>\n","      <td>The sanctions against the school were a punish...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>B</td>\n","      <td>61fe6e879ff18686d7552425a36344c8</td>\n","      <td>people</td>\n","      <td>[{'label': 'A', 'text': 'race track'}, {'label...</td>\n","      <td>Sammy wanted to go to where the people were.  ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>A</td>\n","      <td>4c1cb0e95b99f72d55c068ba0255c54d</td>\n","      <td>choker</td>\n","      <td>[{'label': 'A', 'text': 'jewelry store'}, {'la...</td>\n","      <td>To locate a choker not located in a jewelry bo...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>D</td>\n","      <td>02e821a3e53cb320790950aab4489e85</td>\n","      <td>highway</td>\n","      <td>[{'label': 'A', 'text': 'united states'}, {'la...</td>\n","      <td>Google Maps and other highway and street GPS s...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>C</td>\n","      <td>23505889b94e880c3e89cff4ba119860</td>\n","      <td>fox</td>\n","      <td>[{'label': 'A', 'text': 'pretty flowers.'}, {'...</td>\n","      <td>The fox walked from the city into the forest, ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  answerKey  ...                                               stem\n","0         A  ...  The sanctions against the school were a punish...\n","1         B  ...  Sammy wanted to go to where the people were.  ...\n","2         A  ...  To locate a choker not located in a jewelry bo...\n","3         D  ...  Google Maps and other highway and street GPS s...\n","4         C  ...  The fox walked from the city into the forest, ...\n","\n","[5 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"e6igx61hld2U"},"source":["## Steps\n","\n","1. Import training examples\n","2. Process it\n","    - Format input into something BERT can work with, including `[CLS]` and `[SEP]`\n","    - We were thinking which label is correct: \n","    - Tokenize \n","    - Create an output layer using softmax. \n","3. Train it\n","    - Specify how many layers of BERT to fine tune\n","    "]},{"cell_type":"markdown","metadata":{"id":"VPkzLy1Dld2U"},"source":["# BERT base model (uncased)\n","\n","From: https://huggingface.co/bert-base-uncased\n","\n","> Pretrained model on English language using a masked language modeling (MLM) objective. It was introduced in this paper and first released in this repository. This model is uncased: it does not make a difference between english and English.\n","> \n","> Disclaimer: The team releasing BERT did not write a model card for this model so this model card has been written by the Hugging Face team."]},{"cell_type":"markdown","metadata":{"id":"VefgfZHjld2V"},"source":["For each question, there are five answer choices. Only one of them is correct.\n","\n","For BERT, the first thought was to have all five answers attached to each question, and the model would choose one of the five responses. This is how it's originally done in the CommonsenseQA paper.\n","\n","```\n","[CLS] Question text here [SEP] Ans choice A [SEP] Ans choice B [SEP] Ans choice C [SEP] Ans choice D [SEP] Ans choice E [SEP]\n","```\n","\n","It seems complicated, however, and requires a significant lift. So for now, let me try creating five question-answer pairs for each question. Like this:\n","\n","```\n","[CLS] Question text here [SEP] Ans choice A [SEP]\n","[CLS] Question text here [SEP] Ans choice B [SEP]\n","[CLS] Question text here [SEP] Ans choice C [SEP]\n","[CLS] Question text here [SEP] Ans choice D [SEP]\n","[CLS] Question text here [SEP] Ans choice E [SEP]\n","```\n","\n","Only one of the above 5 inputs will have a positive label for being the correct answer. The rest will have 0. The problem with this model is that we're evaluating each choice separately to see if it looks like a right answer at all. But I think it's important for the model to know how the answer choices compare to each other as well.\n"]},{"cell_type":"code","metadata":{"id":"FYemdu1Ild2V","executionInfo":{"status":"ok","timestamp":1603701863229,"user_tz":420,"elapsed":10152,"user":{"displayName":"Haerang Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0EKtbt3OiquluDVkbIbNSiQmtCnognF7CujF_=s64","userId":"05995372446527155749"}}},"source":["tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n","lab_order = {\"A\": 0, \"B\":1, \"C\":2, \"D\":3, \"E\":4}\n","\n","class InputExample(object):\n","    \"\"\"A single multiple choice question and its five multiple choice answer candidates\"\"\"\n","    # This class is adapted from https://github.com/jonathanherzig/commonsenseqa/blob/master/bert/run_commonsense_qa.py\n","    # and from https://github.com/rodgzilla/pytorch-pretrained-BERT/blob/dcb50eaa4b80d3ab75d373c36780c80fb47cfd97/examples/run_swag.py\n","\n","    def __init__(\n","            self,\n","            qid,\n","            question,\n","            choice_0,\n","            choice_1,\n","            choice_2,\n","            choice_3,\n","            choice_4,\n","            label=None):\n","        \"\"\"Construct an instance.\"\"\"\n","        self.qid = qid\n","        self.question = question  # e.g., 'The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change?'\n","        self.choices = [          # All five anser choices as a list\n","            choice_0,\n","            choice_1,\n","            choice_2,\n","            choice_3,\n","            choice_4\n","        ]\n","        self.label = label        # \n","        \n","    def __str__(self):\n","        return self.__repr__()\n","\n","    def __repr__(self):\n","        l = [\n","            f\"qid: {self.qid}\",\n","            f\"question: {self.question}\",\n","            f\"choice_0: {self.choices[0]}\",\n","            f\"choice_1: {self.choices[1]}\",\n","            f\"choice_2: {self.choices[2]}\",\n","            f\"choice_3: {self.choices[3]}\",\n","            f\"choice_4: {self.choices[4]}\",\n","        ]\n","\n","        if self.label is not None:\n","            l.append(f\"label: {self.label}\")\n","\n","        return \", \".join(l)    \n","\n","class InputFeatures(object):\n","    \"\"\"Adapted from: https://github.com/rodgzilla/pytorch-pretrained-BERT/blob/dcb50eaa4b80d3ab75d373c36780c80fb47cfd97/examples/run_swag.py\n","    Stores Bert model inputs (ids, masks) for each example\"\"\"\n","    \n","    def __init__(self,\n","                 example_id,\n","                 choices_features,\n","                 label\n","\n","    ):\n","        self.example_id = example_id\n","        self.choices_features = [\n","            {\n","                'input_ids': input_ids,\n","                'input_mask': input_mask,\n","                'segment_ids': segment_ids\n","            }\n","            for _, input_ids, input_mask, segment_ids in choices_features\n","        ]\n","        self.label = label\n","\n","    \n","def process_examples(data):\n","    \"\"\"Given the examples in a pandas df format, process examples into example class\"\"\"\n","    examples = []\n","    labels = []\n","    questions = []\n","    anscands = []\n","    \n","    \n","    for index, row in data.iterrows(): \n","        example = InputExample(\n","                    qid=row.id,\n","                    question=row.stem,\n","                    choice_0=str(row.choices[0]).replace(\"'\",\"\"),\n","                    choice_1=str(row.choices[1]).replace(\"'\",\"\"),\n","                    choice_2=str(row.choices[2]).replace(\"'\",\"\"),\n","                    choice_3=str(row.choices[3]).replace(\"'\",\"\"),\n","                    choice_4=str(row.choices[4]).replace(\"'\",\"\"),\n","                    label=lab_order[row.answerKey]\n","                )\n","        examples.append(example)\n","        \n","    return examples \n","\n","def convert_examples_to_features(examples, tokenizer, max_seq_length, is_training):\n","    # For each quesiton, we generate five inputs: one for each answer choice. \n","    \n","    # - [CLS] question [SEP] choice_1 [SEP]\n","    # - [CLS] question [SEP] choice_2 [SEP]\n","    # - [CLS] question [SEP] choice_3 [SEP]\n","    # - [CLS] question [SEP] choice_4 [SEP]\n","    # - [CLS] question [SEP] choice_5 [SEP]\n","    \n","    features = []\n","    # Loop through questions\n","    for example_index, example in enumerate(examples):\n","        question_tokens = tokenizer.tokenize(example.question)\n","\n","        choices_features = []\n","        # For each question, loop through all answer choices \n","        for choice_index, choice in enumerate(example.choices):\n","            # We create a copy of the question tokens in order to be\n","            # able to shrink it according to choice_tokens\n","            question_tokens_choice = question_tokens[:]\n","            choice_tokens = tokenizer.tokenize(choice)\n","            # Modifies `question_tokens_choice` and `choice_tokens` in\n","            # place so that the total length is less than the\n","            # specified length.  Account for [CLS], [SEP], [SEP] with\n","            # \"- 3\"\n","            _truncate_seq_pair(question_tokens_choice, choice_tokens, max_seq_length - 3)\n","\n","            tokens = [\"[CLS]\"] + question_tokens_choice + [\"[SEP]\"] + choice_tokens + [\"[SEP]\"]\n","            segment_ids = [0] * (len(question_tokens_choice) + 2) + [1] * (len(choice_tokens) + 1)\n","\n","            input_ids = tokenizer.convert_tokens_to_ids(tokens)\n","            input_mask = [1] * len(input_ids)\n","\n","            # Zero-pad up to the sequence length.\n","            padding = [0] * (max_seq_length - len(input_ids))\n","            input_ids += padding\n","            input_mask += padding\n","            segment_ids += padding\n","\n","            assert len(input_ids) == max_seq_length\n","            assert len(input_mask) == max_seq_length\n","            assert len(segment_ids) == max_seq_length\n","\n","            choices_features.append((tokens, input_ids, input_mask, segment_ids))\n","\n","        label = example.label\n","\n","        features.append(\n","            InputFeatures(\n","                example_id = example.qid,\n","                choices_features = choices_features,\n","                label = label\n","            )\n","        )\n","\n","    return features\n","\n","\n","def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n","    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n","\n","    # This is a simple heuristic which will always truncate the longer sequence\n","    # one token at a time. This makes more sense than truncating an equal percent\n","    # of tokens from each, since if one sequence is very short then each token\n","    # that's truncated likely contains more information than a longer sequence.\n","    while True:\n","        total_length = len(tokens_a) + len(tokens_b)\n","        if total_length <= max_length:\n","            break\n","        if len(tokens_a) > len(tokens_b):\n","            tokens_a.pop()\n","        else:\n","            tokens_b.pop()\n","            \n","def select_field(features, field):\n","    \"\"\"Yields a list, length equal to the total number of examples,\n","    where each item is a list of arrays,\n","    each array representing the feature array\"\"\"\n","    return [\n","        [\n","            choice[field]   # Grab the feature array of that choice.\n","            for choice in feature.choices_features  # Loop through 5 choices of that example\n","        ]\n","        for feature in features   # loop through each example\n","    ]\n","\n"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"7aKR77U_ld2Y","executionInfo":{"status":"ok","timestamp":1603701877565,"user_tz":420,"elapsed":24480,"user":{"displayName":"Haerang Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0EKtbt3OiquluDVkbIbNSiQmtCnognF7CujF_=s64","userId":"05995372446527155749"}}},"source":["# Process inputs \n","\n","train_examples= process_examples(train)\n","train_features = convert_examples_to_features(\n","                    examples=train_examples, \n","                    tokenizer=tokenizer, \n","                    max_seq_length=50, \n","                    is_training=True)\n","\n","dev_examples= process_examples(dev)\n","dev_features = convert_examples_to_features(\n","                    examples=dev_examples, \n","                    tokenizer=tokenizer, \n","                    max_seq_length=50, \n","                    is_training=True)\n"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"aJ0jMNNbDwP1","executionInfo":{"status":"ok","timestamp":1603701877567,"user_tz":420,"elapsed":24471,"user":{"displayName":"Haerang Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0EKtbt3OiquluDVkbIbNSiQmtCnognF7CujF_=s64","userId":"05995372446527155749"}},"outputId":"bceadb61-c380-45cf-83a9-c21df9efa3a3","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["len(dev_examples)"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1221"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"hzd9D659EGPW","executionInfo":{"status":"ok","timestamp":1603701877568,"user_tz":420,"elapsed":24465,"user":{"displayName":"Haerang Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0EKtbt3OiquluDVkbIbNSiQmtCnognF7CujF_=s64","userId":"05995372446527155749"}},"outputId":"e022e8f5-c85c-4b07-8153-d975eaee54f6","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["len(dev_features)"],"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1221"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"TK2jrjkZDxLr","executionInfo":{"status":"ok","timestamp":1603701877568,"user_tz":420,"elapsed":24457,"user":{"displayName":"Haerang Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0EKtbt3OiquluDVkbIbNSiQmtCnognF7CujF_=s64","userId":"05995372446527155749"}},"outputId":"d963b2ab-5a7a-4938-c634-001c4354058d","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["len(train_examples)"],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["9741"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"HyM73LKZEInU","executionInfo":{"status":"ok","timestamp":1603701877569,"user_tz":420,"elapsed":24450,"user":{"displayName":"Haerang Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0EKtbt3OiquluDVkbIbNSiQmtCnognF7CujF_=s64","userId":"05995372446527155749"}},"outputId":"65735d06-5875-4b0e-a49d-da339a2d7f98","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["len(train_features)"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["9741"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"fh1Dlse1ENOm","executionInfo":{"status":"ok","timestamp":1603701877569,"user_tz":420,"elapsed":24443,"user":{"displayName":"Haerang Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0EKtbt3OiquluDVkbIbNSiQmtCnognF7CujF_=s64","userId":"05995372446527155749"}}},"source":[""],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"STXPhHvtld2a","executionInfo":{"status":"ok","timestamp":1603701877569,"user_tz":420,"elapsed":24434,"user":{"displayName":"Haerang Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0EKtbt3OiquluDVkbIbNSiQmtCnognF7CujF_=s64","userId":"05995372446527155749"}}},"source":["def create_inputs_from_features(features):\n","    input_ids = torch.tensor(select_field(features, 'input_ids'), dtype=torch.long)\n","    input_mask = torch.tensor(select_field(features, 'input_mask'), dtype=torch.long)\n","    segment_ids = torch.tensor(select_field(features, 'segment_ids'), dtype=torch.long)\n","    label = torch.tensor([f.label for f in features], dtype=torch.long)\n","    \n","    return input_ids, input_mask, segment_ids, label\n","\n"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"PWhIaRGOld2c","executionInfo":{"status":"ok","timestamp":1603701877907,"user_tz":420,"elapsed":24765,"user":{"displayName":"Haerang Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0EKtbt3OiquluDVkbIbNSiQmtCnognF7CujF_=s64","userId":"05995372446527155749"}}},"source":["all_input_ids, all_input_mask, all_segment_ids, all_label = create_inputs_from_features(train_features)\n","train_data = [all_input_ids, all_input_mask, all_segment_ids, all_label]\n","dev_data = list(create_inputs_from_features(dev_features))\n"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"5l1NqyG9aPr_","executionInfo":{"status":"ok","timestamp":1603701877908,"user_tz":420,"elapsed":24759,"user":{"displayName":"Haerang Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0EKtbt3OiquluDVkbIbNSiQmtCnognF7CujF_=s64","userId":"05995372446527155749"}}},"source":[""],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"iB6Ufw4Hld2f","executionInfo":{"status":"ok","timestamp":1603701877909,"user_tz":420,"elapsed":24752,"user":{"displayName":"Haerang Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0EKtbt3OiquluDVkbIbNSiQmtCnognF7CujF_=s64","userId":"05995372446527155749"}},"outputId":"4eecde36-05f3-495f-ba9f-cd1ba3da4c23","colab":{"base_uri":"https://localhost:8080/","height":87}},"source":["print(all_input_ids.shape)\n","print(all_input_mask.shape)\n","print(all_segment_ids.shape)\n","print(all_label.shape)\n"],"execution_count":32,"outputs":[{"output_type":"stream","text":["torch.Size([9741, 5, 50])\n","torch.Size([9741, 5, 50])\n","torch.Size([9741, 5, 50])\n","torch.Size([9741])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sR2U5oHYaKE2","executionInfo":{"status":"ok","timestamp":1603701877910,"user_tz":420,"elapsed":24743,"user":{"displayName":"Haerang Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0EKtbt3OiquluDVkbIbNSiQmtCnognF7CujF_=s64","userId":"05995372446527155749"}},"outputId":"5555cc57-1190-4528-d8a2-7476722b232c","colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["print(dev_data[0].shape)\n","print(train_data[0].shape)"],"execution_count":33,"outputs":[{"output_type":"stream","text":["torch.Size([1221, 5, 50])\n","torch.Size([9741, 5, 50])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TnaJxOOvld2h","executionInfo":{"status":"ok","timestamp":1603701877912,"user_tz":420,"elapsed":24735,"user":{"displayName":"Haerang Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0EKtbt3OiquluDVkbIbNSiQmtCnognF7CujF_=s64","userId":"05995372446527155749"}}},"source":["from transformers import BertForMultipleChoice"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hy1kGx7rld2i","executionInfo":{"status":"ok","timestamp":1603701894173,"user_tz":420,"elapsed":40988,"user":{"displayName":"Haerang Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0EKtbt3OiquluDVkbIbNSiQmtCnognF7CujF_=s64","userId":"05995372446527155749"}},"outputId":"04b23008-c227-45cd-edba-d3a2d12f4089","colab":{"base_uri":"https://localhost:8080/","height":124}},"source":["model = BertForMultipleChoice.from_pretrained('bert-base-uncased')"],"execution_count":35,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMultipleChoice: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n","- This IS NOT expected if you are initializing BertForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForMultipleChoice were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"OoyjNzG-xjSl","executionInfo":{"status":"ok","timestamp":1603701894174,"user_tz":420,"elapsed":40979,"user":{"displayName":"Haerang Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0EKtbt3OiquluDVkbIbNSiQmtCnognF7CujF_=s64","userId":"05995372446527155749"}},"outputId":"29acdec3-ee4c-4976-943b-8d4a697e8154","colab":{"base_uri":"https://localhost:8080/","height":87}},"source":["# Which layers are learnable?\n","\n","def show_learnable_layers(model):\n","  counter_learnable = defaultdict(int)\n","  counter_frozen = defaultdict(int)\n","\n","  for name, param in model.named_parameters():\n","      if param.requires_grad==True:\n","          if \"bert\" in name:\n","            counter_learnable[\"bert\"] += 1 \n","          else:\n","            counter_learnable[name] += 1 \n","      else:\n","          if \"bert\" in name:\n","            counter_frozen[\"bert\"] += 1 \n","          else:\n","            counter_frozen[name] += 1 \n","  print(\"Learnable params\")\n","  print(counter_learnable)\n","  print(\"Frozen params\")\n","  print(counter_frozen)\n","\n","show_learnable_layers(model)"],"execution_count":36,"outputs":[{"output_type":"stream","text":["Learnable params\n","defaultdict(<class 'int'>, {'bert': 199, 'classifier.weight': 1, 'classifier.bias': 1})\n","Frozen params\n","defaultdict(<class 'int'>, {})\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"c4DTh75RxZZJ","executionInfo":{"status":"ok","timestamp":1603701894175,"user_tz":420,"elapsed":40969,"user":{"displayName":"Haerang Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0EKtbt3OiquluDVkbIbNSiQmtCnognF7CujF_=s64","userId":"05995372446527155749"}},"outputId":"6acdb896-b114-4f6b-f851-e15be069bb2f","colab":{"base_uri":"https://localhost:8080/","height":87}},"source":["# Freeze layers. \n","\n","for param in model.bert.parameters():\n","    param.requires_grad = False\n","\n","show_learnable_layers(model)"],"execution_count":37,"outputs":[{"output_type":"stream","text":["Learnable params\n","defaultdict(<class 'int'>, {'classifier.weight': 1, 'classifier.bias': 1})\n","Frozen params\n","defaultdict(<class 'int'>, {'bert': 199})\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"d7EnsR2Tld2m"},"source":["Output is of the class `MultipleChoiceModelOutput`. It contains the following elements:\n","\n","            loss=loss,\n","            logits=reshaped_logits,\n","            hidden_states=outputs.hidden_states,\n","            attentions=outputs.attentions,\n","        \n"]},{"cell_type":"markdown","metadata":{"id":"6AtPb4Huld2p"},"source":["Let's see if we can train it some more. I would like it to do a couple rounds of the following.\n","\n","1. Forward pass to make predictions\n","2. Calculate loss\n","3. Backward pass: compute gradient of the loss with respect to all the learnable parameters of the model.\n"]},{"cell_type":"code","metadata":{"id":"u8nVeTxD5Y06","executionInfo":{"status":"ok","timestamp":1603701894176,"user_tz":420,"elapsed":40959,"user":{"displayName":"Haerang Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0EKtbt3OiquluDVkbIbNSiQmtCnognF7CujF_=s64","userId":"05995372446527155749"}},"outputId":"5b437237-e39a-4cb9-feae-15312b512507","colab":{"base_uri":"https://localhost:8080/","height":55}},"source":["# Set up optimizer \n","from pytorch_pretrained_bert.optimization import BertAdam\n","\n","no_decay = ['bias', 'gamma', 'beta']\n","num_train_steps = 100\n","\n","t_total = num_train_steps\n","param_optimizer = list(model.named_parameters())\n","optimizer_grouped_parameters = [\n","        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay_rate': 0.01},\n","        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay_rate': 0.0}\n","        ]\n","optimizer = BertAdam(optimizer_grouped_parameters,\n","                         lr=args.learning_rate,\n","                         warmup=args.warmup_proportion,\n","                         t_total=t_total)"],"execution_count":38,"outputs":[{"output_type":"stream","text":["10/26/2020 08:44:53 - INFO - pytorch_pretrained_bert.modeling -   Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"-vDLQXBl4jqa","outputId":"a0e1d719-7c88-48b8-cb17-9bf453d270e9","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# Update loss at every epoch rather than little batches. \n","\n","num_epochs=3\n","\n","for epoch in range(num_epochs):\n","  print(datetime.now(pytz.timezone('US/Pacific')).strftime(\"%Y%m%d_%H%M%S\"))\n","  len_dataset = all_input_ids.shape[0]\n","\n","  output = model.forward(\n","        input_ids=all_input_ids,\n","        attention_mask=all_input_mask,\n","        token_type_ids=all_segment_ids,\n","        position_ids=None,\n","        head_mask=None,\n","        inputs_embeds=None,\n","        labels=all_label,\n","        output_attentions=None,\n","        output_hidden_states=None,\n","        return_dict=True,\n","    )\n","  loss = output[\"loss\"]\n","\n","  print(epoch, loss.item())\n","  \n","\n","  # Before backward pass, zero all gradients for variables it will update \n","  optimizer.zero_grad()   \n","\n","  # Backward pass\n","  loss.backward()\n","\n","  # Update weights \n","  optimizer.step()\n","\n","  # Log the training loss\n","  writer.add_scalar('training loss', loss.item(), epoch)\n","  \n","  # Evaluate against dev data \n","  dev_output = model.forward(\n","        input_ids=dev_data[0],\n","        attention_mask=dev_data[1],\n","        token_type_ids=dev_data[2],\n","        labels=dev_data[3],\n","        output_attentions=None,\n","        output_hidden_states=None,\n","        return_dict=True,\n","    )\n","\n","  # Log the dev loss\n","  writer.add_scalar('dev loss', dev_output[\"loss\"].item(), epoch)\n","  \n"," \n","  # Show the answer choice with the highest score for each question \n","  train_predictions = torch.argmax(torch.nn.functional.softmax(output[\"logits\"]), dim=1)\n","  dev_predictions = torch.argmax(torch.nn.functional.softmax(dev_output[\"logits\"]), dim=1)\n","  \n","   # Accuracy against train data\n","  train_accuracy = metrics.accuracy_score(all_label, train_predictions)\n","  \n","  # Log accuracy against train data\n","  writer.add_scalar('train accuracy', train_accuracy, epoch)\n","  \n","  # Accuracy against dev data\n","  dev_accuracy = metrics.accuracy_score(dev_data[3], dev_predictions)\n","  \n","  # Log accuracy against dev data\n","  writer.add_scalar('dev accuracy', dev_accuracy, epoch)\n","  \n","  "],"execution_count":null,"outputs":[{"output_type":"stream","text":["20201026_014453\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7SaHRhGB9HY1"},"source":["dev_predictions"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J1uJCZEY44rB"},"source":["# Save model\n","torch.save(model.state_dict(), \"models/\"+NAME)\n","\n","# Save dev predictions \n","fordump = dev_output \n","dir = \"models/predictions/\"\n","filename = \"{NAME}_{ver}_dev_predictions\".format(NAME=NAME, ver=runtype)\n","pickle_out = open(dir + filename, \"wb\")\n","pickle.dump(fordump, pickle_out)\n","pickle_out.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kzJbIBqw4uBC"},"source":["# # Load model code snippet\n","\n","# loadmodel = BertForMultipleChoice.from_pretrained('bert-base-uncased')\n","# loadmodel.load_state_dict(torch.load(\"models/\"+NAME))\n","\n","# loadmodel_output = loadmodel.forward(\n","#         input_ids=dev_data[0],\n","#         attention_mask=dev_data[1],\n","#         token_type_ids=dev_data[2],\n","#         labels=dev_data[3],\n","#         output_attentions=None,\n","#         output_hidden_states=None,\n","#         return_dict=True,\n","#     )\n","\n","# loadmodel_output_predictions = torch.argmax(torch.nn.functional.softmax(loadmodel_output[\"logits\"]), dim=1)\n","# print(loadmodel_output_predictions)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OV3gsfdplDxr"},"source":["%tensorboard --logdir \"runs/\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XBOELi92lSBm"},"source":["# Error analysis\n","\n","# incorrect_idxs = [i for i, prediction in enumerate(predictions) if prediction != targets[i]]\n","# for incorrect_idx in incorrect_idxs:\n","#     print(tokenizer.decode(valid_dataset[incorrect_idx]['input_ids']))\n","#     print(\"Target Answer: {}\".format(tokenizer.decode(valid_dataset[incorrect_idx]['target_ids'])))\n","#     print(\"Predicted Answer: {}\".format(predictions[incorrect_idx]))"],"execution_count":null,"outputs":[]}]}