{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT - Out of the Box\n",
    "\n",
    "In this notebook, we will test the performance of an out-of-the-box BERT model on CommonsenseQA. I follow the tutorial here: https://github.com/jalammar/jalammar.github.io/blob/master/notebooks/bert/A_Visual_Notebook_to_Using_BERT_for_the_First_Time.ipynb\n",
    "\n",
    "I've implemented the Hugginface transformers library. \n",
    "\n",
    "I referred to the Commonsense QA repo and code to understand how the authors of this work establiahsed their baseline using BERT. This is the link to their code: https://github.com/jonathanherzig/commonsenseqa/blob/master/bert/run_commonsense_qa.py\n",
    "\n",
    "From this repo (README): https://github.com/jonathanherzig/commonsenseqa\n",
    "\n",
    "Their work is far more advanced and complicated than maybe what I want to do at this time. But I refer to their work to understand the set up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# import torch\n",
    "import transformers as ppb\n",
    "import warnings\n",
    "\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "# BertModel, \\\n",
    "# DistilBertModel, DistilBertTokenizer, \\\n",
    "# AutoTokenizer, AutoModelWithLMHead\n",
    "\n",
    "\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from IPython.display import Image \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", \n",
    "      len(tf.config.experimental.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num CPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num CPUs Available: \",\n",
    "      len(tf.config.experimental.list_physical_devices('CPU')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dataset\n",
    "\n",
    "It's in the dataset folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answerKey</th>\n",
       "      <th>id</th>\n",
       "      <th>question_concept</th>\n",
       "      <th>choices</th>\n",
       "      <th>stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>075e483d21c29a511267ef62bedc0461</td>\n",
       "      <td>punishing</td>\n",
       "      <td>[{'label': 'A', 'text': 'ignore'}, {'label': '...</td>\n",
       "      <td>The sanctions against the school were a punish...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>61fe6e879ff18686d7552425a36344c8</td>\n",
       "      <td>people</td>\n",
       "      <td>[{'label': 'A', 'text': 'race track'}, {'label...</td>\n",
       "      <td>Sammy wanted to go to where the people were.  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>4c1cb0e95b99f72d55c068ba0255c54d</td>\n",
       "      <td>choker</td>\n",
       "      <td>[{'label': 'A', 'text': 'jewelry store'}, {'la...</td>\n",
       "      <td>To locate a choker not located in a jewelry bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D</td>\n",
       "      <td>02e821a3e53cb320790950aab4489e85</td>\n",
       "      <td>highway</td>\n",
       "      <td>[{'label': 'A', 'text': 'united states'}, {'la...</td>\n",
       "      <td>Google Maps and other highway and street GPS s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C</td>\n",
       "      <td>23505889b94e880c3e89cff4ba119860</td>\n",
       "      <td>fox</td>\n",
       "      <td>[{'label': 'A', 'text': 'pretty flowers.'}, {'...</td>\n",
       "      <td>The fox walked from the city into the forest, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  answerKey                                id question_concept  \\\n",
       "0         A  075e483d21c29a511267ef62bedc0461        punishing   \n",
       "1         B  61fe6e879ff18686d7552425a36344c8           people   \n",
       "2         A  4c1cb0e95b99f72d55c068ba0255c54d           choker   \n",
       "3         D  02e821a3e53cb320790950aab4489e85          highway   \n",
       "4         C  23505889b94e880c3e89cff4ba119860              fox   \n",
       "\n",
       "                                             choices  \\\n",
       "0  [{'label': 'A', 'text': 'ignore'}, {'label': '...   \n",
       "1  [{'label': 'A', 'text': 'race track'}, {'label...   \n",
       "2  [{'label': 'A', 'text': 'jewelry store'}, {'la...   \n",
       "3  [{'label': 'A', 'text': 'united states'}, {'la...   \n",
       "4  [{'label': 'A', 'text': 'pretty flowers.'}, {'...   \n",
       "\n",
       "                                                stem  \n",
       "0  The sanctions against the school were a punish...  \n",
       "1  Sammy wanted to go to where the people were.  ...  \n",
       "2  To locate a choker not located in a jewelry bo...  \n",
       "3  Google Maps and other highway and street GPS s...  \n",
       "4  The fox walked from the city into the forest, ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = '../dataset/train_rand_split.jsonl'\n",
    "\n",
    "def load_data(file):\n",
    "\n",
    "    lines = []\n",
    "    with open(file, 'rb') as json_file:\n",
    "        for json_line in json_file:\n",
    "            lines.append(json.loads(json_line))\n",
    "        data = json_normalize(lines)\n",
    "        data.columns = data.columns.map(lambda x: x.split(\".\")[-1])\n",
    "    return data\n",
    "\n",
    "train = load_data(file)\n",
    "dev = load_data('../dataset/dev_rand_split.jsonl')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT base model (cased)\n",
    "\n",
    "From: https://huggingface.co/bert-base-cased\n",
    "\n",
    "> Pretrained model on English language using a masked language modeling (MLM) objective. It was introduced in this paper and first released in this repository. \n",
    "> \n",
    "> Disclaimer: The team releasing BERT did not write a model card for this model so this model card has been written by the Hugging Face team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcaf6165ef2344f5b9bae72c1eb7acae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descriptiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "lab_order = {\"A\": 0, \"B\":1, \"C\":2, \"D\":3, \"E\":4}\n",
    "\n",
    "class InputExample(object):\n",
    "    \"\"\"A single multiple choice question.\"\"\"\n",
    "    # This class is adapted from https://github.com/jonathanherzig/commonsenseqa/blob/master/bert/run_commonsense_qa.py\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            qid,\n",
    "            question,\n",
    "            answer,\n",
    "            label):\n",
    "        \"\"\"Construct an instance.\"\"\"\n",
    "        self.qid = qid\n",
    "        self.question = question  # e.g., 'The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change?'\n",
    "        self.answer = answer      # e.g., \"ignore\" if choice label is A \n",
    "        self.label = label        # e.g., If correct answer, 1. Otherwise 0. \n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"QUESTION: {}\\nANSWER  : {}\\nLABEL   : {}\".format(self.question, self.answer, self.label)\n",
    "    \n",
    "    \n",
    "def create_example(row, choice_num):\n",
    "    qid = row.id\n",
    "    \n",
    "    # Question: Just take it from stem \n",
    "    question = row.stem\n",
    "    \n",
    "    # Answer choice \n",
    "    label = int(row[\"answerKey\"] == choice_num)  # If the answer key is equal to the answer choice number, mark 1 \n",
    "    answer = row[\"choices\"][lab_order[choice_num]][\"text\"]         # actual ans text \n",
    "    \n",
    "    return InputExample(qid, question, answer, label) \n",
    "    \n",
    "    \n",
    "def process_examples(data):\n",
    "    examples = []\n",
    "    labels = []\n",
    "    questions = []\n",
    "    anscands = []\n",
    "    \n",
    "    \n",
    "    for index, row in data.iterrows(): \n",
    "        for letter in lab_order.keys():\n",
    "            example = create_example(row, letter)\n",
    "            examples.append(example)\n",
    "            \n",
    "            questions.append(example.question)\n",
    "            anscands.append(example.answer)\n",
    "            labels.append(example.label)\n",
    "            \n",
    "            \n",
    "        \n",
    "    encoded_example = tokenizer(questions, anscands, \n",
    "                                            padding=True, \n",
    "                                            truncation=True, \n",
    "                                            return_tensors='tf')\n",
    "            \n",
    "    return examples, encoded_example, labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process dev and training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_eg, dev_encoded_eg, dev_labs = process_examples(dev)\n",
    "train_eg, train_encoded_eg, train_labs = process_examples(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.tokenization_utils_base.BatchEncoding"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_encoded_eg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_encoded_eg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.EagerTensor"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_encoded_eg[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.EagerTensor"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_encoded_eg[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fb6305e3af0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get length of all the question + answer in the train set\n",
    "seq_len = [len(i.question) + len(i.answer) for i in train_eg]\n",
    "\n",
    "pd.Series(seq_len).hist(bins = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "388"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: I dno't want to use 388 because too sparse. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Game plan\n",
    "\n",
    "I'll be following the tutorial on: http://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/, but for specifically commonsenseQA. Here are the steps from the tutorial.\n",
    "\n",
    "1. Embed all sentences. Let's look at the output from the BERT model for our inputs. \n",
    "2. The tutorial says do a train/test split. We don't need this 'cause our data came separate.\n",
    "3. Train the logistic regressio model using the training set. This is training on the output of BERT. I will need to create a FFNN to attach at the end of BERT. See what it comes back with. \n",
    "4. (Optional for now) For each question, pick the answer with the highest score. \n",
    "5. Then, evaluate against true answers. The evaluation metric will be % of questions with the correct answers out of all questions. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Embed all sentences. \n",
    "\n",
    "I've already formatted the CommonsenseQA inpts to be fed into the BERT model. Let's look at the output from the BERT model for our inputs. It should have a 768-long vector for each input token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "bert_model = TFBertModel.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 100\n",
    "\n",
    "bert_inputs_dev_tiny = {\"input_ids\": dev_encoded_eg[\"input_ids\"][:size,:], \\\n",
    "                          \"token_type_ids\": dev_encoded_eg[\"token_type_ids\"][:size,:], \\\n",
    "                          \"attention_mask\": dev_encoded_eg[\"attention_mask\"][:size,:]}\n",
    "\n",
    "bert_labs_dev_tiny = dev_labs[:size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 100\n",
    "\n",
    "bert_inputs_train_tiny = {\"input_ids\": train_encoded_eg[\"input_ids\"][:size,:], \\\n",
    "                          \"token_type_ids\": train_encoded_eg[\"token_type_ids\"][:size,:], \\\n",
    "                          \"attention_mask\": train_encoded_eg[\"attention_mask\"][:size,:]}\n",
    "\n",
    "bert_labs_train_tiny = train_labs[:size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bert (TFBertMainLayer)       multiple                  108310272 \n",
      "=================================================================\n",
      "Total params: 108,310,272\n",
      "Trainable params: 108,310,272\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bert_model.summary()  # only works if tfbertmodel not pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[48705,76,768] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:ResourceGather]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-9cf1d3f0a5e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# of the bert model!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mbert_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_encoded_eg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#bert_inputs_train_tiny)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'oob_bert_output_768.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/transformers/modeling_tf_bert.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    795\u001b[0m     )\n\u001b[1;32m    796\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/transformers/modeling_tf_bert.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[1;32m    592\u001b[0m             \u001b[0mtoken_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m         \u001b[0membedding_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;31m# We create a 3D attention mask from a 2D tensor mask.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/transformers/modeling_tf_bert.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input_ids, position_ids, token_type_ids, inputs_embeds, mode, training)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \"\"\"\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"embedding\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"linear\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_linear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/transformers/modeling_tf_bert.py\u001b[0m in \u001b[0;36m_embedding\u001b[0;34m(self, input_ids, position_ids, token_type_ids, inputs_embeds, training)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mgather_v2\u001b[0;34m(params, indices, validate_indices, axis, batch_dims, name)\u001b[0m\n\u001b[1;32m   4687\u001b[0m               \u001b[0mbatch_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4688\u001b[0m               name=None):\n\u001b[0;32m-> 4689\u001b[0;31m   return gather(\n\u001b[0m\u001b[1;32m   4690\u001b[0m       \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4691\u001b[0m       \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mgather\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   4674\u001b[0m     \u001b[0;31m# TODO(apassos) find a less bad way of detecting resource variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4675\u001b[0m     \u001b[0;31m# without introducing a circular dependency.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4676\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4677\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4678\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36msparse_read\u001b[0;34m(self, indices, name)\u001b[0m\n\u001b[1;32m    685\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Gather\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m       \u001b[0mvariable_accessed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m       value = gen_resource_variable_ops.resource_gather(\n\u001b[0m\u001b[1;32m    688\u001b[0m           self._handle, indices, dtype=self._dtype, name=name)\n\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py\u001b[0m in \u001b[0;36mresource_gather\u001b[0;34m(resource, indices, dtype, batch_dims, validate_indices, name)\u001b[0m\n\u001b[1;32m    554\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6841\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6842\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6843\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6844\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[48705,76,768] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:ResourceGather]"
     ]
    }
   ],
   "source": [
    "# Each example has 68 tokens for dev and 75 tokens for train \n",
    "# Each token yields a vector of 768 numbers after coming out\n",
    "# of the bert model!\n",
    "\n",
    "bert_out = bert_model(train_encoded_eg)#bert_inputs_train_tiny)\n",
    "\n",
    "with open('oob_bert_output_768.pkl', 'wb') as file:\n",
    "    pickle.dump(bert_out, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(bert_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_out[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract just the CLS token for all examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = bert_out[0][:,0,:]\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do a logistic regression. \n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(features, train_labs)\n",
    "\n",
    "# filename = 'oob_bert_with_logisticregression.sav'\n",
    "# pickle.dump(lr_clf, open(filename, 'wb'), encoding=\"UTF-8\")\n",
    "\n",
    "with open('oob_bert_with_logisticregression.pkl', 'wb') as file:\n",
    "    pickle.dump(lr_clf, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.score(features, train_encoded_eg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_features = bert_model(dev_encoded_eg)[0][:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.score(dev_features, dev_labs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
