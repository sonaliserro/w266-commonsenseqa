{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT - Out of the Box\n",
    "\n",
    "In this notebook, we will test the performance of an out-of-the-box BERT model on CommonsenseQA. I follow the tutorial here: https://github.com/jalammar/jalammar.github.io/blob/master/notebooks/bert/A_Visual_Notebook_to_Using_BERT_for_the_First_Time.ipynb\n",
    "\n",
    "I've implemented the Hugginface transformers library. \n",
    "\n",
    "I referred to the Commonsense QA repo and code to understand how the authors of this work establiahsed their baseline using BERT. This is the link to their code: https://github.com/jonathanherzig/commonsenseqa/blob/master/bert/run_commonsense_qa.py\n",
    "\n",
    "From this repo (README): https://github.com/jonathanherzig/commonsenseqa\n",
    "\n",
    "Their work is far more advanced and complicated than maybe what I want to do at this time. But I refer to their work to understand the set up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/haeranglee/anaconda3/lib/python3.8/site-packages (3.3.1)\n",
      "Requirement already satisfied: tokenizers==0.8.1.rc2 in /home/haeranglee/anaconda3/lib/python3.8/site-packages (from transformers) (0.8.1rc2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/haeranglee/anaconda3/lib/python3.8/site-packages (from transformers) (4.47.0)\n",
      "Requirement already satisfied: packaging in /home/haeranglee/anaconda3/lib/python3.8/site-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in /home/haeranglee/anaconda3/lib/python3.8/site-packages (from transformers) (0.1.91)\n",
      "Requirement already satisfied: filelock in /home/haeranglee/anaconda3/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: numpy in /home/haeranglee/anaconda3/lib/python3.8/site-packages (from transformers) (1.18.5)\n",
      "Requirement already satisfied: requests in /home/haeranglee/anaconda3/lib/python3.8/site-packages (from transformers) (2.24.0)\n",
      "Requirement already satisfied: sacremoses in /home/haeranglee/anaconda3/lib/python3.8/site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/haeranglee/anaconda3/lib/python3.8/site-packages (from transformers) (2020.6.8)\n",
      "Requirement already satisfied: six in /home/haeranglee/anaconda3/lib/python3.8/site-packages (from packaging->transformers) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/haeranglee/anaconda3/lib/python3.8/site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/haeranglee/anaconda3/lib/python3.8/site-packages (from requests->transformers) (1.25.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/haeranglee/anaconda3/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/haeranglee/anaconda3/lib/python3.8/site-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/haeranglee/anaconda3/lib/python3.8/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: click in /home/haeranglee/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /home/haeranglee/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers) (0.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.2; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the '/home/haeranglee/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-1.6.0-cp38-cp38-manylinux1_x86_64.whl (748.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 748.8 MB 6.7 kB/s  eta 0:00:01   |█                               | 24.4 MB 6.2 MB/s eta 0:01:57     |█▋                              | 38.1 MB 6.2 MB/s eta 0:01:55     |█████▍                          | 124.9 MB 16.7 MB/s eta 0:00:38     |████████▏                       | 191.6 MB 68.2 MB/s eta 0:00:09     |████████▍                       | 197.5 MB 68.2 MB/s eta 0:00:09     |███████████▍                    | 267.5 MB 39.8 MB/s eta 0:00:13     |████████████▏                   | 285.9 MB 39.8 MB/s eta 0:00:12     |████████████▌                   | 293.6 MB 39.8 MB/s eta 0:00:12     |██████████████▉                 | 348.2 MB 12.3 MB/s eta 0:00:33     |███████████████▍                | 360.7 MB 64.3 MB/s eta 0:00:07     |████████████████                | 373.7 MB 64.3 MB/s eta 0:00:06     |████████████████▉               | 395.0 MB 64.3 MB/s eta 0:00:06     |██████████████████▏             | 426.0 MB 11.1 MB/s eta 0:00:30     |██████████████████▌             | 433.2 MB 11.1 MB/s eta 0:00:29     |██████████████████▉             | 440.4 MB 11.1 MB/s eta 0:00:28     |███████████████████             | 445.2 MB 11.1 MB/s eta 0:00:28     |███████████████████████         | 538.3 MB 40.9 MB/s eta 0:00:06     |███████████████████████▏        | 543.1 MB 40.9 MB/s eta 0:00:06     |████████████████████████▍       | 571.1 MB 40.9 MB/s eta 0:00:05     |████████████████████████▉       | 580.9 MB 8.6 MB/s eta 0:00:20     |█████████████████████████▏      | 588.0 MB 8.6 MB/s eta 0:00:19     |█████████████████████████▌      | 597.9 MB 8.6 MB/s eta 0:00:18     |██████████████████████████▌     | 620.2 MB 51.7 MB/s eta 0:00:03     |███████████████████████████     | 629.5 MB 51.7 MB/s eta 0:00:03     |███████████████████████████▍    | 641.5 MB 51.7 MB/s eta 0:00:03     |███████████████████████████▌    | 643.9 MB 51.7 MB/s eta 0:00:03     |████████████████████████████▏   | 658.6 MB 51.7 MB/s eta 0:00:02     |█████████████████████████████▋  | 692.2 MB 39.4 MB/s eta 0:00:02     |██████████████████████████████  | 704.2 MB 56.9 MB/s eta 0:00:01     |██████████████████████████████▌ | 713.2 MB 56.9 MB/s eta 0:00:01     |███████████████████████████████▊| 743.1 MB 56.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/haeranglee/anaconda3/lib/python3.8/site-packages (from torch) (1.18.5)\n",
      "Requirement already satisfied: future in /home/haeranglee/anaconda3/lib/python3.8/site-packages (from torch) (0.18.2)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.6.0\n",
      "\u001b[33mWARNING: You are using pip version 20.2.2; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the '/home/haeranglee/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import torch\n",
    "import transformers as ppb\n",
    "import warnings\n",
    "\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dataset\n",
    "\n",
    "It's in the dataset folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answerKey</th>\n",
       "      <th>id</th>\n",
       "      <th>question_concept</th>\n",
       "      <th>choices</th>\n",
       "      <th>stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>075e483d21c29a511267ef62bedc0461</td>\n",
       "      <td>punishing</td>\n",
       "      <td>[{'label': 'A', 'text': 'ignore'}, {'label': '...</td>\n",
       "      <td>The sanctions against the school were a punish...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>61fe6e879ff18686d7552425a36344c8</td>\n",
       "      <td>people</td>\n",
       "      <td>[{'label': 'A', 'text': 'race track'}, {'label...</td>\n",
       "      <td>Sammy wanted to go to where the people were.  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>4c1cb0e95b99f72d55c068ba0255c54d</td>\n",
       "      <td>choker</td>\n",
       "      <td>[{'label': 'A', 'text': 'jewelry store'}, {'la...</td>\n",
       "      <td>To locate a choker not located in a jewelry bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D</td>\n",
       "      <td>02e821a3e53cb320790950aab4489e85</td>\n",
       "      <td>highway</td>\n",
       "      <td>[{'label': 'A', 'text': 'united states'}, {'la...</td>\n",
       "      <td>Google Maps and other highway and street GPS s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C</td>\n",
       "      <td>23505889b94e880c3e89cff4ba119860</td>\n",
       "      <td>fox</td>\n",
       "      <td>[{'label': 'A', 'text': 'pretty flowers.'}, {'...</td>\n",
       "      <td>The fox walked from the city into the forest, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  answerKey                                id question_concept  \\\n",
       "0         A  075e483d21c29a511267ef62bedc0461        punishing   \n",
       "1         B  61fe6e879ff18686d7552425a36344c8           people   \n",
       "2         A  4c1cb0e95b99f72d55c068ba0255c54d           choker   \n",
       "3         D  02e821a3e53cb320790950aab4489e85          highway   \n",
       "4         C  23505889b94e880c3e89cff4ba119860              fox   \n",
       "\n",
       "                                             choices  \\\n",
       "0  [{'label': 'A', 'text': 'ignore'}, {'label': '...   \n",
       "1  [{'label': 'A', 'text': 'race track'}, {'label...   \n",
       "2  [{'label': 'A', 'text': 'jewelry store'}, {'la...   \n",
       "3  [{'label': 'A', 'text': 'united states'}, {'la...   \n",
       "4  [{'label': 'A', 'text': 'pretty flowers.'}, {'...   \n",
       "\n",
       "                                                stem  \n",
       "0  The sanctions against the school were a punish...  \n",
       "1  Sammy wanted to go to where the people were.  ...  \n",
       "2  To locate a choker not located in a jewelry bo...  \n",
       "3  Google Maps and other highway and street GPS s...  \n",
       "4  The fox walked from the city into the forest, ...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = '../dataset/train_rand_split.jsonl'\n",
    "def load_data(file):\n",
    "\n",
    "    lines = []\n",
    "    with open(file, 'rb') as json_file:\n",
    "        for json_line in json_file:\n",
    "            lines.append(json.loads(json_line))\n",
    "        data = json_normalize(lines)\n",
    "        data.columns = data.columns.map(lambda x: x.split(\".\")[-1])\n",
    "    return data\n",
    "\n",
    "train = load_data(file)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9741, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = data\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = train.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'A', 'text': 'ignore'},\n",
       " {'label': 'B', 'text': 'enforce'},\n",
       " {'label': 'C', 'text': 'authoritarian'},\n",
       " {'label': 'D', 'text': 'yell at'},\n",
       " {'label': 'E', 'text': 'avoid'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data.choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[0][\"stem\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'A', 'text': 'ignore'},\n",
       " {'label': 'B', 'text': 'enforce'},\n",
       " {'label': 'C', 'text': 'authoritarian'},\n",
       " {'label': 'D', 'text': 'yell at'},\n",
       " {'label': 'E', 'text': 'avoid'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[0][\"choices\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'punishing'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[0][\"question_concept\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps\n",
    "\n",
    "1. Import training examples\n",
    "2. Process it\n",
    "    - Format input into something BERT can work with, including `[CLS]` and `[SEP]`\n",
    "    - We were thinking which label is correct: \n",
    "    - Tokenize \n",
    "    - Create an output layer using softmax. \n",
    "3. Train it\n",
    "    - Specify how many layers of BERT to fine tune\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answerKey</th>\n",
       "      <th>id</th>\n",
       "      <th>question_concept</th>\n",
       "      <th>choices</th>\n",
       "      <th>stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>075e483d21c29a511267ef62bedc0461</td>\n",
       "      <td>punishing</td>\n",
       "      <td>[{'label': 'A', 'text': 'ignore'}, {'label': '...</td>\n",
       "      <td>The sanctions against the school were a punish...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>61fe6e879ff18686d7552425a36344c8</td>\n",
       "      <td>people</td>\n",
       "      <td>[{'label': 'A', 'text': 'race track'}, {'label...</td>\n",
       "      <td>Sammy wanted to go to where the people were.  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>4c1cb0e95b99f72d55c068ba0255c54d</td>\n",
       "      <td>choker</td>\n",
       "      <td>[{'label': 'A', 'text': 'jewelry store'}, {'la...</td>\n",
       "      <td>To locate a choker not located in a jewelry bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D</td>\n",
       "      <td>02e821a3e53cb320790950aab4489e85</td>\n",
       "      <td>highway</td>\n",
       "      <td>[{'label': 'A', 'text': 'united states'}, {'la...</td>\n",
       "      <td>Google Maps and other highway and street GPS s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C</td>\n",
       "      <td>23505889b94e880c3e89cff4ba119860</td>\n",
       "      <td>fox</td>\n",
       "      <td>[{'label': 'A', 'text': 'pretty flowers.'}, {'...</td>\n",
       "      <td>The fox walked from the city into the forest, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  answerKey                                id question_concept  \\\n",
       "0         A  075e483d21c29a511267ef62bedc0461        punishing   \n",
       "1         B  61fe6e879ff18686d7552425a36344c8           people   \n",
       "2         A  4c1cb0e95b99f72d55c068ba0255c54d           choker   \n",
       "3         D  02e821a3e53cb320790950aab4489e85          highway   \n",
       "4         C  23505889b94e880c3e89cff4ba119860              fox   \n",
       "\n",
       "                                             choices  \\\n",
       "0  [{'label': 'A', 'text': 'ignore'}, {'label': '...   \n",
       "1  [{'label': 'A', 'text': 'race track'}, {'label...   \n",
       "2  [{'label': 'A', 'text': 'jewelry store'}, {'la...   \n",
       "3  [{'label': 'A', 'text': 'united states'}, {'la...   \n",
       "4  [{'label': 'A', 'text': 'pretty flowers.'}, {'...   \n",
       "\n",
       "                                                stem  \n",
       "0  The sanctions against the school were a punish...  \n",
       "1  Sammy wanted to go to where the people were.  ...  \n",
       "2  To locate a choker not located in a jewelry bo...  \n",
       "3  Google Maps and other highway and street GPS s...  \n",
       "4  The fox walked from the city into the forest, ...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT base model (uncased)\n",
    "\n",
    "From: https://huggingface.co/bert-base-uncased\n",
    "\n",
    "> Pretrained model on English language using a masked language modeling (MLM) objective. It was introduced in this paper and first released in this repository. This model is uncased: it does not make a difference between english and English.\n",
    "> \n",
    "> Disclaimer: The team releasing BERT did not write a model card for this model so this model card has been written by the Hugging Face team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bc5a26722754ede9f27f4cb3c8a42a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee5e4122a1d84acd976a4ab9d11d047a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# model = AutoModelWithLMHead.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "?tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertForMaskedLM(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (cls): BertOnlyMLMHead(\n",
      "    (predictions): BertLMPredictionHead(\n",
      "      (transform): BertPredictionHeadTransform(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      )\n",
      "      (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 7592, 1010, 1045, 1005, 1049, 1037, 2309, 6251, 999, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "# Try encoding something. \n",
    "\n",
    "encoded_input = tokenizer(\"Hello, I'm a single sentence!\")\n",
    "print(encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 101, 7592, 1010, 1045, 1005, 1049, 1037, 2309, 6251, 999, 102, 1998, 1045, 1005, 1049, 1037, 2047, 6251, 999, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "encoded_input = tokenizer(\"[CLS] Hello, I'm a single sentence! [SEP] And I'm a new sentence!\")\n",
    "print(encoded_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I can see it's encoding the sentence. Somehow the tokenizer knew already the beginning was beginning, without me manually putting in `[CLS]`. That's token 101. `[SEP]` is token 102. \n",
    "\n",
    "Not sure why attention mask is always 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1996, 17147, 2114, 1996, 2082, 2020, 1037, 16385, 2075, 6271, 1010, 1998, 2027, 2790, 2000, 2054, 1996, 4073, 1996, 2082, 2018, 2081, 2000, 2689, 1029, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(train.iloc[0][\"stem\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1996, 17147,  2114,  1996,  2082,  2020,  1037, 16385,  2075,\n",
       "          6271,  1010,  1998,  2027,  2790,  2000,  2054,  1996,  4073,  1996,\n",
       "          2082,  2018,  2081,  2000,  2689,  1029,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1]])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PyTorch version \n",
    "tokenizer(train.iloc[0][\"stem\"], return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(1, 27), dtype=int32, numpy=\n",
       "array([[  101,  1996, 17147,  2114,  1996,  2082,  2020,  1037, 16385,\n",
       "         2075,  6271,  1010,  1998,  2027,  2790,  2000,  2054,  1996,\n",
       "         4073,  1996,  2082,  2018,  2081,  2000,  2689,  1029,   102]],\n",
       "      dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(1, 27), dtype=int32, numpy=\n",
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(1, 27), dtype=int32, numpy=\n",
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1]], dtype=int32)>}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TensorFlow version\n",
    "tokenizer(train.iloc[0][\"stem\"], return_tensors='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'sanctions',\n",
       " 'against',\n",
       " 'the',\n",
       " 'school',\n",
       " 'were',\n",
       " 'a',\n",
       " 'punish',\n",
       " '##ing',\n",
       " 'blow',\n",
       " ',',\n",
       " 'and',\n",
       " 'they',\n",
       " 'seemed',\n",
       " 'to',\n",
       " 'what',\n",
       " 'the',\n",
       " 'efforts',\n",
       " 'the',\n",
       " 'school',\n",
       " 'had',\n",
       " 'made',\n",
       " 'to',\n",
       " 'change',\n",
       " '?']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(train.iloc[0][\"stem\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the difference between `tokenizer(sentence)` and `tokenizer.tokenize(sentence)`? Maybe the first is just fetching the ids of the list of tokens. The second is actually tokenizing the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['well', ',', 'here', \"'\", 's', 'a', 'sentence', 'for', 'you']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(\"Well, here's a sentence for you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 7592, 1045, 2572, 1037, 6251, 102]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"Hello I am a sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101,\n",
       " 7592,\n",
       " 1045,\n",
       " 2572,\n",
       " 1037,\n",
       " 6251,\n",
       " 102,\n",
       " 2021,\n",
       " 1045,\n",
       " 2572,\n",
       " 1037,\n",
       " 4435,\n",
       " 2047,\n",
       " 6251,\n",
       " 102]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"Hello I am a sentence\", \"But I am a brand new sentence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each question, there are five answer choices. Only one of them is correct.\n",
    "\n",
    "For BERT, the first thought was to have all five answers attached to each question, and the model would choose one of the five responses. This is how it's originally done in the CommonsenseQA paper.\n",
    "\n",
    "```\n",
    "[CLS] Question text here [SEP] Ans choice A [SEP] Ans choice B [SEP] Ans choice C [SEP] Ans choice D [SEP] Ans choice E [SEP]\n",
    "```\n",
    "\n",
    "It seems complicated, however, and requires a significant lift. So for now, let me try creating five question-answer pairs for each question. Like this:\n",
    "\n",
    "```\n",
    "[CLS] Question text here [SEP] Ans choice A [SEP]\n",
    "[CLS] Question text here [SEP] Ans choice B [SEP]\n",
    "[CLS] Question text here [SEP] Ans choice C [SEP]\n",
    "[CLS] Question text here [SEP] Ans choice D [SEP]\n",
    "[CLS] Question text here [SEP] Ans choice E [SEP]\n",
    "```\n",
    "\n",
    "Only one of the above 5 inputs will have a positive label for being the correct answer. The rest will have 0. The problem with this model is that we're evaluating each choice separately to see if it looks like a right answer at all. But I think it's important for the model to know how the answer choices compare to each other as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['A', 'B', 'C', 'D', 'E'])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab_order.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_order = {\"A\": 0, \"B\":1, \"C\":2, \"D\":3, \"E\":4}\n",
    "\n",
    "class InputExample(object):\n",
    "    \"\"\"A single multiple choice question.\"\"\"\n",
    "    # This class is adapted from https://github.com/jonathanherzig/commonsenseqa/blob/master/bert/run_commonsense_qa.py\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            qid,\n",
    "            question,\n",
    "            answer,\n",
    "            label):\n",
    "        \"\"\"Construct an instance.\"\"\"\n",
    "        self.qid = qid\n",
    "        self.question = question  # e.g., 'The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change?'\n",
    "        self.answer = answer      # e.g., \"ignore\" if choice label is A \n",
    "        self.label = label        # e.g., If correct answer, 1. Otherwise 0. \n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"QUESTION: {}\\nANSWER  : {}\\nLABEL   : {}\".format(self.question, self.answer, self.label)\n",
    "    \n",
    "    \n",
    "def create_example(row, choice_num):\n",
    "    qid = row.id\n",
    "    \n",
    "    # Question: Just take it from stem \n",
    "    question = row.stem\n",
    "    \n",
    "    # Answer choice \n",
    "    label = int(row[\"answerKey\"] == choice_num)  # If the answer key is equal to the answer choice number, mark 1 \n",
    "    answer = row[\"choices\"][lab_order[choice_num]][\"text\"]         # actual ans text \n",
    "    \n",
    "    return InputExample(qid, question, answer, label) \n",
    "    \n",
    "    \n",
    "def process_examples(data):\n",
    "    examples = []\n",
    "    input_ids = []\n",
    "    input_masks = []\n",
    "    input_segment_ids = []\n",
    "    \n",
    "    for index, row in data.iterrows(): \n",
    "        for letter in lab_order.keys():\n",
    "            example = create_example(row, letter)\n",
    "            examples.append(example)\n",
    "        \n",
    "            encoded_example = tokenizer.encode(example.question, example.answer)\n",
    "            input_ids.append(encoded_example)\n",
    "            \n",
    "            # For input mask, create as many 1's as there is data. The rest we will pad with 0\n",
    "            # OK this is DEFINITELY manual and I know there's a better way to do it. \n",
    "            # But I'll figure that out later\n",
    "            input_mask = [1]*len(encoded_example)\n",
    "            input_masks.append(input_mask)\n",
    "            \n",
    "            # For segment IDs, \n",
    "            # question segment (including the [SEP] after it) will have segment ID = 0\n",
    "            # the candidate answer will have segment ID = 1\n",
    "            first_sep_index = encoded_example.index(102)\n",
    "            input_segment_id = [0]*(first_sep_index + 1) + [1]*(len(encoded_example) - first_sep_index - 1)\n",
    "            input_segment_ids.append(input_segment_id)\n",
    "            \n",
    "    # pad the results \n",
    "    MAX_LEN = max([len(eg) for eg in input_ids])\n",
    "\n",
    "    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
    "                                                  value=0, truncating=\"post\", padding=\"post\")\n",
    "    input_masks = pad_sequences(input_masks, maxlen=MAX_LEN, dtype=\"long\", \n",
    "                                                  value=0, truncating=\"post\", padding=\"post\")\n",
    "    input_segment_ids = pad_sequences(input_segment_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
    "                                                  value=0, truncating=\"post\", padding=\"post\")\n",
    "    \n",
    "    return examples, input_ids, input_masks, input_segment_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_example = tokenizer.encode(sample.question, sample.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change?\n",
      "Answer  : ignore\n",
      "Label   : 1\n"
     ]
    }
   ],
   "source": [
    "row = train.iloc[0]\n",
    "sample = create_example(row, \"A\")\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples, train_input_ids, train_input_masks, train_input_segment_ids = process_examples(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some notes**\n",
    "\n",
    "* `example` is the raw example. You can look at the raw data. \n",
    "* Input ID means the concatenated question and answer pairs from the example have been first tokenized, then ID'd. See below for how the raw text, tokens, and IDs translate to each other. \n",
    "* I've padded the data to the max length of the examples. \n",
    "* Segment embedding should be 0 for the first sentence (question) and 1 for the second sentence (answer choice.) \n",
    "* Input mask should be 1 for valid input nad 0 for `[PAD]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION: The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change?\n",
      "ANSWER  : ignore\n",
      "LABEL   : 1\n",
      "\n",
      "Input IDs (token IDs)\n",
      "[  101  1996 17147  2114  1996  2082  2020  1037 16385  2075  6271  1010\n",
      "  1998  2027  2790  2000  2054  1996  4073  1996  2082  2018  2081  2000\n",
      "  2689  1029   102  8568   102     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0]\n",
      "\n",
      "Decoded from input IDs\n",
      "[CLS] the sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? [SEP] ignore [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "\n",
      "Tokens\n",
      "['[CLS]', 'the', 'sanctions', 'against', 'the', 'school', 'were', 'a', 'punish', '##ing', 'blow', ',', 'and', 'they', 'seemed', 'to', 'what', 'the', 'efforts', 'the', 'school', 'had', 'made', 'to', 'change', '?', '[SEP]', 'ignore', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "\n",
      "Input masks\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "\n",
      "Input segment IDs\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n"
     ]
    }
   ],
   "source": [
    "print(train_examples[0])\n",
    "print(\"\\nInput IDs (token IDs)\")\n",
    "print(train_input_ids[0])\n",
    "\n",
    "print(\"\\nDecoded from input IDs\")\n",
    "print(tokenizer.decode(train_input_ids[0]))\n",
    "print(\"\\nTokens\")\n",
    "print(tokenizer.convert_ids_to_tokens(train_input_ids[0]))\n",
    "\n",
    "print(\"\\nInput masks\")\n",
    "print(train_input_masks[0])\n",
    "print(\"\\nInput segment IDs\")\n",
    "print(train_input_segment_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFBertModel \n",
    "\n",
    "# The following code is adapted from W266 BERT notebook\n",
    "# https://github.com/datasci-w266/2020-fall-main/blob/master/materials/Bert/BERT_NER_tf_21_v1.ipynb\n",
    "\n",
    "def classification_model(max_input_length, train_layers, optimizer):\n",
    "    \"\"\"\n",
    "    Implementation of binary classification model\n",
    "    \n",
    "    variables:\n",
    "        max_input_length: number of tokens (max_length + 1)\n",
    "        train_layers: number of layers to be retrained\n",
    "        optimizer: optimizer to be used\n",
    "    \n",
    "    returns: model\n",
    "    \"\"\"\n",
    "\n",
    "    in_id = tf.keras.layers.Input(shape=(max_length,), dtype='int32', name=\"input_ids\")\n",
    "    in_mask = tf.keras.layers.Input(shape=(max_length,), dtype='int32', name=\"input_masks\")\n",
    "    in_segment = tf.keras.layers.Input(shape=(max_length,), dtype='int32', name=\"segment_ids\")\n",
    "    \n",
    "    bert_inputs = [in_id, in_mask, in_segment]\n",
    "    \n",
    "    bert_layer = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "    \n",
    "    \n",
    "    # Freeze layers, i.e. only train number of layers specified, starting from the top\n",
    "    \n",
    "    retrain_layers = []\n",
    "    \n",
    "    for retrain_layer_number in range(train_layers):\n",
    "        \n",
    "        layer_code = '_' + str(11 - retrain_layer_number)\n",
    "        retrain_layers.append(layer_code)\n",
    "    \n",
    "    for w in bert_layer.weights:\n",
    "        if not any([x in w.name for x in retrain_layers]):\n",
    "            w._trainable = False\n",
    "            \n",
    "    # End of freezing section\n",
    "    \n",
    "    bert_sequence = bert_layer(bert_inputs)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f59ac913170d448a9bc6e00f8db6fdd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=536063208.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "bert_layer = TFBertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an attempt at the other input type:\n",
    "\n",
    "\n",
    "```\n",
    "[CLS] Question text here [SEP] Ans choice A [SEP] Ans choice B [SEP] Ans choice C [SEP] Ans choice D [SEP] Ans choice E [SEP]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputExample(object):\n",
    "    \"\"\"A single multiple choice question.\"\"\"\n",
    "    # This function is copied from https://github.com/jonathanherzig/commonsenseqa/blob/master/bert/run_commonsense_qa.py\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            qid,\n",
    "            question,\n",
    "            answers,\n",
    "            label):\n",
    "        \"\"\"Construct an instance.\"\"\"\n",
    "        self.qid = qid\n",
    "        self.question = question\n",
    "        self.answers = answers\n",
    "        self.label = label\n",
    "    \n",
    "    \n",
    "def tokenize_qa(row):\n",
    "    qid = row.id\n",
    "    \n",
    "    # Question: Just take it from stem \n",
    "    question = row.stem\n",
    "    tokens_q = tokenizer.tokenize(question)\n",
    "    \n",
    "    # Answers\n",
    "    # This snippet is adapted from https://github.com/jonathanherzig/commonsenseqa/blob/master/bert/run_commonsense_qa.py\n",
    "    # Take the five responses and convert them into a single array. \n",
    "    # Sort them by ABCDE choice number. \n",
    "    answers = np.array([\n",
    "        choice[\"text\"]\n",
    "        for choice in sorted(\n",
    "            row['choices'],\n",
    "            key=lambda c: c['label'])\n",
    "      ])\n",
    "    \n",
    "#     tokens_a =answers)\n",
    "        \n",
    "    # Here is the answer key \n",
    "    label = row[\"answerKey\"]\n",
    "\n",
    "    # input_ids = tokenizer.encode(tokens_q, tokens_a)\n",
    "        \n",
    "    return InputExample(qid, question, answers, label) \n",
    "    \n",
    "def process_examples(data):\n",
    "    examples = []\n",
    "#     encoded_examples = []\n",
    "    \n",
    "    for index, row in data.iterrows(): \n",
    "        example = tokenize_qa(row)\n",
    "        examples.append(example)\n",
    "        \n",
    "        encoded_example = pad_n_tokenize(example)\n",
    "#         encoded_examples.append(encoded_example)\n",
    "        \n",
    "    return examples#, encoded_examples \n",
    "\n",
    "def example_to_token_ids_segment_ids_label_ids(\n",
    "    ex_index,\n",
    "    example,\n",
    "    max_seq_length,\n",
    "    tokenizer):\n",
    "    # This function is adapted from https://github.com/jonathanherzig/commonsenseqa/blob/master/bert/run_commonsense_qa.py\n",
    "    \n",
    "    \"\"\"Converts an ``InputExample`` to token ids and segment ids.\"\"\"\n",
    "#     if ex_index < 5:\n",
    "#         tf.logging.info(f\"*** Example {ex_index} ***\")\n",
    "#         tf.logging.info(\"qid: %s\" % (example.qid))\n",
    "\n",
    "    question_tokens = tokenizer.tokenize(example.question)\n",
    "    answers_tokens = map(tokenizer.tokenize, example.answers)   # Map b/c there are multiple sentences in here. Tokenizer typically only takes in two segments but we want more.\n",
    "\n",
    "    token_ids = []\n",
    "    segment_ids = []\n",
    "    for choice_idx, answer_tokens in enumerate(answers_tokens):\n",
    "        truncated_question_tokens = question_tokens[\n",
    "            :max((max_seq_length - 3)//2, max_seq_length - (len(answer_tokens) + 3))]\n",
    "        truncated_answer_tokens = answer_tokens[\n",
    "            :max((max_seq_length - 3)//2, max_seq_length - (len(question_tokens) + 3))]\n",
    "\n",
    "        choice_tokens = []\n",
    "        choice_segment_ids = []\n",
    "        choice_tokens.append(\"[CLS]\")\n",
    "        choice_segment_ids.append(0)\n",
    "        for question_token in truncated_question_tokens:\n",
    "            choice_tokens.append(question_token)\n",
    "            choice_segment_ids.append(0)\n",
    "        choice_tokens.append(\"[SEP]\")\n",
    "        choice_segment_ids.append(0)\n",
    "        for answer_token in truncated_answer_tokens:\n",
    "            choice_tokens.append(answer_token)\n",
    "            choice_segment_ids.append(1)\n",
    "        choice_tokens.append(\"[SEP]\")\n",
    "        choice_segment_ids.append(1)\n",
    "\n",
    "        choice_token_ids = tokenizer.convert_tokens_to_ids(choice_tokens)\n",
    "\n",
    "        token_ids.append(choice_token_ids)\n",
    "        segment_ids.append(choice_segment_ids)\n",
    "\n",
    "        if ex_index < 5:\n",
    "            tf.logging.info(\"choice %s\" % choice_idx)\n",
    "            tf.logging.info(\"tokens: %s\" % \" \".join(\n",
    "                [tokenization.printable_text(t) for t in choice_tokens]))\n",
    "            tf.logging.info(\"token ids: %s\" % \" \".join(\n",
    "                [str(x) for x in choice_token_ids]))\n",
    "            tf.logging.info(\"segment ids: %s\" % \" \".join(\n",
    "                [str(x) for x in choice_segment_ids]))\n",
    "\n",
    "    label_ids = [example.label]\n",
    "\n",
    "    if ex_index < 5:\n",
    "        tf.logging.info(\"label: %s (id = %d)\" % (example.label, label_ids[0]))\n",
    "\n",
    "    return token_ids, segment_ids, label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.InputExample at 0x7f1dc61c7a00>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = train.iloc[0]\n",
    "tokenize_qa(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = train.iloc[0]\n",
    "tokenize_qa(row)\n",
    "sample = tokenize_qa(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = train.iloc[0]\n",
    "tokenize_qa(row)\n",
    "sample = tokenize_qa(row)\n",
    "# train_examples = process_examples(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.InputExample at 0x7f1e94132310>,\n",
       " <__main__.InputExample at 0x7f1ddc0a6790>,\n",
       " <__main__.InputExample at 0x7f1ddc0a67f0>,\n",
       " <__main__.InputExample at 0x7f1ddc0a6910>,\n",
       " <__main__.InputExample at 0x7f1ddc0a6b20>]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_examples[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have to pad the examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change?'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_examples[0].question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ignore', 'enforce', 'authoritarian', 'yell at', 'avoid'],\n",
       "      dtype='<U13')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_examples[0].answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ignore enforce authoritarian yell at avoid\n"
     ]
    }
   ],
   "source": [
    "print(*train_examples[0].answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.encode(train_examples[0].question, *train_examples[0].answers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
